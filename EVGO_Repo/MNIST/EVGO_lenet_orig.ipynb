{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "import os\n",
    "import keras\n",
    "import pickle\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import initializers\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='mnist.pkl.gz'\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "lr = 0.1\n",
    "lr2 = 0.02\n",
    "lr3 = 0.7\n",
    "eps = 0.1\n",
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "print('... loading data')\n",
    "\n",
    "# Load the dataset\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    except:\n",
    "        train_set, valid_set, test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 28, 28, 1)\n",
      "50000 train samples\n",
      "10000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train) = train_set\n",
    "(x_test, y_test) = test_set\n",
    "(x_val, y_val) = valid_set\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    x_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28, 1),\n",
       " (50000, 10),\n",
       " (10000, 28, 28, 1),\n",
       " (10000, 10),\n",
       " (10000, 28, 28, 1),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 1),\n",
       " (50000, 10),\n",
       " (10000, 32, 32, 1),\n",
       " (10000, 10),\n",
       " (10000, 32, 32, 1),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_val = np.pad(x_val, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(setseed):\n",
    "    \"\"\"\n",
    "    Builds test Keras model for LeNet MNIST\n",
    "    :param loss (str): Type of loss - must be one of Keras accepted keras losses\n",
    "    :return: Keras dense model of predefined structure\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(6, (3,3), activation='relu', kernel_initializer=initializers.lecun_uniform(seed = setseed))(input)\n",
    "    avg1 = AveragePooling2D()(conv1)\n",
    "    conv2 = Conv2D(16, (3,3), activation='relu', kernel_initializer=initializers.lecun_uniform(seed = setseed))(avg1)\n",
    "    avg2 = AveragePooling2D()(conv2)\n",
    "    flat= Flatten()(avg2)\n",
    "    dens1=Dense(units=120, activation='relu')(flat)\n",
    "    dens2=Dense(units=84, activation='relu')(dens1)\n",
    "    probs=Dense(num_classes, activation='softmax')(dens2)\n",
    "    \n",
    "    model = Model(input=input, output=probs)\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikarabayir\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "all_model = [None,None,None]\n",
    "losses = [None,None,None]\n",
    "\n",
    "prediction=[]\n",
    "\n",
    "all_score =[0,0,0]\n",
    "gr=[]\n",
    "wr=[]\n",
    "xwr=[]\n",
    "\n",
    "for i in range(3):\n",
    "    np.random.seed(25+i)\n",
    "    model = build_model(i+2)\n",
    "    all_model[i]=model\n",
    "    \n",
    "for i in range(3):    \n",
    "    weights = all_model[i].trainable_weights # weight tensors\n",
    "    weights = [weight for weight in weights] # filter down weights tensors to only ones which are trainable\n",
    "    gradients = all_model[i].optimizer.get_gradients(all_model[i].total_loss, weights) # gradient tensors\n",
    "    gr.append(gradients)\n",
    "    wr.append(weights)\n",
    "    xweights = all_model[i].non_trainable_weights # weight tensors\n",
    "    xweights = [weight for weight in xweights] # filter down weights tensors to only ones which are trainable\n",
    "    xwr.append(xweights)\n",
    "\n",
    "    losses[i]=all_model[i].total_loss\n",
    "    prediction.append(all_model[i].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.3922014174782826\n",
      "train acc score is :0.8760390025575447\n",
      "It has been 9.605804681777954 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.15452594646618148\n",
      "val acc score is :0.9406645569620253\n",
      "test\n",
      "test loss score is :0.15095577745026426\n",
      "test acc score is :0.9408623417721519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 1/100 [00:11<18:20, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.14550746086022587\n",
      "train acc score is :0.9544637148337596\n",
      "It has been 6.017298460006714 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.15083223409196245\n",
      "val acc score is :0.9442246835443038\n",
      "test\n",
      "test loss score is :0.15176973952852849\n",
      "test acc score is :0.9449169303797469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 2/100 [00:18<16:20, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.11127573617583955\n",
      "train acc score is :0.9654931265984654\n",
      "It has been 5.876711130142212 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.09523267195489304\n",
      "val acc score is :0.9587618670886076\n",
      "test\n",
      "test loss score is :0.08866520966344242\n",
      "test acc score is :0.9619264240506329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                               | 3/100 [00:25<14:46,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.07025132268248006\n",
      "train acc score is :0.9774216751918159\n",
      "It has been 5.9017174243927 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.059132029440937726\n",
      "val acc score is :0.9715189873417721\n",
      "test\n",
      "test loss score is :0.05980773251267928\n",
      "test acc score is :0.9697389240506329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 4/100 [00:32<13:40,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.049767421459352784\n",
      "train acc score is :0.9837156329923273\n",
      "It has been 5.872528553009033 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04526026962955683\n",
      "val acc score is :0.9760680379746836\n",
      "test\n",
      "test loss score is :0.04094717564469106\n",
      "test acc score is :0.9752768987341772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                              | 5/100 [00:40<12:55,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.039978178575813005\n",
      "train acc score is :0.9863730818414322\n",
      "It has been 5.770548105239868 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05068695295714078\n",
      "val acc score is :0.974189082278481\n",
      "test\n",
      "test loss score is :0.04201530666780198\n",
      "test acc score is :0.9750791139240507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▉                                                                             | 6/100 [00:47<12:16,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.031645633458919686\n",
      "train acc score is :0.9893702046035806\n",
      "It has been 5.731639623641968 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.040903039132830644\n",
      "val acc score is :0.9768591772151899\n",
      "test\n",
      "test loss score is :0.033018085521666476\n",
      "test acc score is :0.9786392405063291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                            | 7/100 [00:54<11:45,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.02583183161661272\n",
      "train acc score is :0.9913882672634271\n",
      "It has been 5.923309326171875 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05434074494221448\n",
      "val acc score is :0.9737935126582279\n",
      "test\n",
      "test loss score is :0.04270585750147134\n",
      "test acc score is :0.9756724683544303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▌                                                                           | 8/100 [01:01<11:28,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.021769454958044766\n",
      "train acc score is :0.992307384910486\n",
      "It has been 5.996698617935181 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.0450904571533769\n",
      "val acc score is :0.9760680379746836\n",
      "test\n",
      "test loss score is :0.040134050270330304\n",
      "test acc score is :0.9775514240506329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                          | 9/100 [01:08<11:16,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.01816833685146278\n",
      "train acc score is :0.9935861572890026\n",
      "It has been 5.865622043609619 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.03898478883638745\n",
      "val acc score is :0.9797270569620253\n",
      "test\n",
      "test loss score is :0.030497980957609142\n",
      "test acc score is :0.9788370253164557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 10/100 [01:15<11:03,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.014848221244964549\n",
      "train acc score is :0.9943654092071611\n",
      "It has been 5.953390121459961 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.043034800404205306\n",
      "val acc score is :0.9779469936708861\n",
      "test\n",
      "test loss score is :0.03529470359395027\n",
      "test acc score is :0.9791337025316456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▉                                                                        | 11/100 [01:23<10:54,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.013664440374554651\n",
      "train acc score is :0.9947650255754475\n",
      "It has been 5.942792654037476 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04329808258584699\n",
      "val acc score is :0.9775514240506329\n",
      "test\n",
      "test loss score is :0.033977589443669\n",
      "test acc score is :0.9791337025316456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 12/100 [01:30<10:45,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.010786364407642135\n",
      "train acc score is :0.9957041240409207\n",
      "It has been 5.8440327644348145 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04354593515745364\n",
      "val acc score is :0.9786392405063291\n",
      "test\n",
      "test loss score is :0.03341770078863986\n",
      "test acc score is :0.9795292721518988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 13/100 [01:37<10:32,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.009272697827583515\n",
      "train acc score is :0.9960437979539642\n",
      "It has been 5.72327733039856 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04201943859525891\n",
      "val acc score is :0.9785403481012658\n",
      "test\n",
      "test loss score is :0.03477835204876677\n",
      "test acc score is :0.9795292721518988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 14/100 [01:44<10:18,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.008127986006327826\n",
      "train acc score is :0.9967631074168798\n",
      "It has been 5.7172229290008545 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05083849962618013\n",
      "val acc score is :0.9757713607594937\n",
      "test\n",
      "test loss score is :0.04644963368950294\n",
      "test acc score is :0.9773536392405063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 15/100 [01:51<10:08,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.007183950643412128\n",
      "train acc score is :0.9968030690537084\n",
      "It has been 5.681736707687378 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.040295572490563994\n",
      "val acc score is :0.9787381329113924\n",
      "test\n",
      "test loss score is :0.03556547051865189\n",
      "test acc score is :0.9793314873417721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 16/100 [01:58<09:57,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.006406187927449399\n",
      "train acc score is :0.997082800511509\n",
      "It has been 6.380690574645996 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04510708557501247\n",
      "val acc score is :0.9790348101265823\n",
      "test\n",
      "test loss score is :0.04043484195777706\n",
      "test acc score is :0.9790348101265823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 17/100 [02:06<10:06,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.005170897209665219\n",
      "train acc score is :0.9976222826086957\n",
      "It has been 6.471017360687256 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04386535472725813\n",
      "val acc score is :0.9791337025316456\n",
      "test\n",
      "test loss score is :0.04316711658363222\n",
      "test acc score is :0.9780458860759493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 18/100 [02:14<10:13,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0045710539368818345\n",
      "train acc score is :0.9978620524296675\n",
      "It has been 6.466979742050171 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05497384028253288\n",
      "val acc score is :0.9771558544303798\n",
      "test\n",
      "test loss score is :0.04108545654678063\n",
      "test acc score is :0.9788370253164557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                 | 19/100 [02:22<10:13,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.004130111418224102\n",
      "train acc score is :0.9976023017902813\n",
      "It has been 6.598526477813721 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04866721472542481\n",
      "val acc score is :0.9775514240506329\n",
      "test\n",
      "test loss score is :0.04680696585591583\n",
      "test acc score is :0.9773536392405063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 20/100 [02:30<10:14,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.004177904894279489\n",
      "train acc score is :0.9978021099744245\n",
      "It has been 6.534743070602417 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05441911145821387\n",
      "val acc score is :0.979628164556962\n",
      "test\n",
      "test loss score is :0.0495637159321635\n",
      "test acc score is :0.9776503164556962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                | 21/100 [02:38<10:13,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0030912528107764864\n",
      "train acc score is :0.998141783887468\n",
      "It has been 6.44199538230896 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.051711750546645265\n",
      "val acc score is :0.9783425632911392\n",
      "test\n",
      "test loss score is :0.04334591405509118\n",
      "test acc score is :0.9795292721518988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 22/100 [02:45<10:06,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.002621958550583298\n",
      "train acc score is :0.998321611253197\n",
      "It has been 6.36050820350647 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.057322251527659344\n",
      "val acc score is :0.9771558544303798\n",
      "test\n",
      "test loss score is :0.048707464059808\n",
      "test acc score is :0.9781447784810127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                              | 23/100 [02:53<09:58,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0013612318924460759\n",
      "train acc score is :0.9986612851662404\n",
      "It has been 6.405409336090088 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04547366607421548\n",
      "val acc score is :0.9806170886075949\n",
      "test\n",
      "test loss score is :0.03869447314548468\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 24/100 [03:01<09:52,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0011489189220771116\n",
      "train acc score is :0.998701246803069\n",
      "It has been 6.469574451446533 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04828746716736267\n",
      "val acc score is :0.9795292721518988\n",
      "test\n",
      "test loss score is :0.04000004906633934\n",
      "test acc score is :0.9805181962025317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                            | 25/100 [03:09<09:44,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0007126630088201925\n",
      "train acc score is :0.9988810741687979\n",
      "It has been 6.607730388641357 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04804855584612651\n",
      "val acc score is :0.9801226265822784\n",
      "test\n",
      "test loss score is :0.04046539728772625\n",
      "test acc score is :0.9811115506329114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 26/100 [03:17<09:41,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0007890325776663624\n",
      "train acc score is :0.9988411125319693\n",
      "It has been 6.470431566238403 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05692962480228559\n",
      "val acc score is :0.9784414556962026\n",
      "test\n",
      "test loss score is :0.045680475636097846\n",
      "test acc score is :0.9794303797468354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▊                                                           | 27/100 [03:25<09:33,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.001243409099286584\n",
      "train acc score is :0.9986213235294118\n",
      "It has been 6.381854295730591 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.047019945996160106\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.0412649017984225\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 28/100 [03:32<09:22,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0004209920255996132\n",
      "train acc score is :0.9989609974424553\n",
      "It has been 6.472296237945557 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.04825947086367169\n",
      "val acc score is :0.9804193037974683\n",
      "test\n",
      "test loss score is :0.04194454447835735\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                         | 29/100 [03:40<09:16,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0003012889346650762\n",
      "train acc score is :0.9989809782608695\n",
      "It has been 6.358656167984009 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05006887618656482\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.04293258381936608\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 30/100 [03:48<09:07,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.00026026894228091684\n",
      "train acc score is :0.9989809782608695\n",
      "It has been 6.237864255905151 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05235423524174936\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.044553170846000606\n",
      "test acc score is :0.9812104430379747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                        | 31/100 [03:56<08:55,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.00020758659313992154\n",
      "train acc score is :0.9990209398976982\n",
      "It has been 6.499837875366211 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05221563993719325\n",
      "val acc score is :0.9804193037974683\n",
      "test\n",
      "test loss score is :0.04427340316194472\n",
      "test acc score is :0.9810126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 32/100 [04:04<08:50,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.00015117149369897934\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.382952451705933 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05438855454916318\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.04472752972917449\n",
      "test acc score is :0.9811115506329114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                      | 33/100 [04:11<08:42,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0001431868668033028\n",
      "train acc score is :0.9990009590792839\n",
      "It has been 6.455143213272095 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05397533176114071\n",
      "val acc score is :0.9804193037974683\n",
      "test\n",
      "test loss score is :0.04438075082002283\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 34/100 [04:19<08:35,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :0.0001586369774344048\n",
      "train acc score is :0.9990209398976982\n",
      "It has been 6.339306354522705 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05483140723311097\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.04602954412751422\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 35/100 [04:27<08:24,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :9.802191922996694e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.362221717834473 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05539553350063727\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.04612103382312358\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 36/100 [04:35<08:15,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :8.974491152126457e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.497333765029907 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.056530613044362577\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.04678909512809307\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▉                                                   | 37/100 [04:42<08:11,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :7.730693133257633e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.328399658203125 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05713685506627886\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.04754009298393273\n",
      "test acc score is :0.9810126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 38/100 [04:50<08:01,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :7.144227774623421e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.376283645629883 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05648652836720275\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.04763293855999332\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▌                                                 | 39/100 [04:58<07:51,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :8.216024040753637e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.363823890686035 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05671538579701814\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.04770675503308828\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                | 40/100 [05:06<07:43,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :6.221646448915713e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.326303482055664 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05691208185260031\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.04758169609595657\n",
      "test acc score is :0.9810126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                               | 41/100 [05:13<07:36,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :5.434089530099544e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.430616855621338 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05742051865362932\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.048178719128752844\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                               | 42/100 [05:21<07:31,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :4.99795877390391e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.4170684814453125 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.0576645953026213\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.048218097029085076\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▊                                              | 43/100 [05:29<07:24,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :5.003186767286476e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.3706934452056885 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05764814593472879\n",
      "val acc score is :0.9804193037974683\n",
      "test\n",
      "test loss score is :0.04837980273953955\n",
      "test acc score is :0.9810126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▋                                             | 44/100 [05:37<07:15,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :4.51531973330575e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.358737230300903 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.058117083578916755\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.048569503739940956\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                            | 45/100 [05:44<07:06,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :4.1045387476074525e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.338179349899292 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.058306029586311044\n",
      "val acc score is :0.9803204113924051\n",
      "test\n",
      "test loss score is :0.048907984752671385\n",
      "test acc score is :0.9810126582278481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▎                                           | 46/100 [05:52<06:57,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.906588424361308e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.341234922409058 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05864526219833457\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.049140920349922845\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████                                           | 47/100 [06:00<06:49,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.7507921127547066e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.395273923873901 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05959440556709317\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.04966578747937563\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▉                                          | 48/100 [06:08<06:43,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.521404906942154e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.373394727706909 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.05973058697839673\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.050037020679413444\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▋                                         | 49/100 [06:15<06:36,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.36478281207406e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.5461649894714355 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.059376333452669315\n",
      "val acc score is :0.9801226265822784\n",
      "test\n",
      "test loss score is :0.04966639128858399\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▌                                        | 50/100 [06:23<06:30,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.2276961662327516e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.4797186851501465 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06037443518763108\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.050467299256582276\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████▎                                       | 51/100 [06:31<06:23,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.138992675298001e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.407407760620117 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06058474406505687\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.05067754757677777\n",
      "test acc score is :0.9809137658227848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████                                       | 52/100 [06:39<06:15,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :3.0252793826874092e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.450092554092407 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06068662822738162\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.050816541742850815\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▉                                      | 53/100 [06:47<06:05,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.772289165828215e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.257207870483398 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06020415887462499\n",
      "val acc score is :0.9802215189873418\n",
      "test\n",
      "test loss score is :0.05062501594122191\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▋                                     | 54/100 [06:54<05:55,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.756405153264313e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.317277908325195 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06035991718172692\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05070419680082581\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▌                                    | 55/100 [07:02<05:45,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.6600407544426408e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.485034942626953 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06106231643005236\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05137423304753142\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▎                                   | 56/100 [07:10<05:39,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.5242387096622646e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.290403127670288 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06131219307781646\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05158782145953055\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▏                                  | 57/100 [07:17<05:31,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.505569197313909e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.379875898361206 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.061000272555919784\n",
      "val acc score is :0.9801226265822784\n",
      "test\n",
      "test loss score is :0.051444670994472544\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▉                                  | 58/100 [07:25<05:24,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.3949452627841807e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.372006893157959 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06162536746754813\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05187658129343071\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▊                                 | 59/100 [07:33<05:16,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.2574866614082414e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.300890207290649 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06193016580697217\n",
      "val acc score is :0.9801226265822784\n",
      "test\n",
      "test loss score is :0.05216653141369505\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▌                                | 60/100 [07:41<05:08,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.2355055422120905e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.421586990356445 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06186786391450064\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05220388285553461\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████▍                               | 61/100 [07:48<05:02,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.1505830251763002e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.440184831619263 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.061956507020100575\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05222021777943841\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▏                              | 62/100 [07:56<04:54,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.1043418174111354e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.434678554534912 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06222153063416196\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.052462658452494516\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████                              | 63/100 [08:04<04:48,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :2.0303584032281052e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.550657033920288 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.061846822148705405\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.052286245621933486\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▊                             | 64/100 [08:12<04:41,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.9650592153863524e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.374886989593506 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06202077143480501\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05242963584515536\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▋                            | 65/100 [08:20<04:32,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.930826288065195e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.506185293197632 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06263719426089076\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.052876184806974355\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▍                           | 66/100 [08:27<04:24,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.8296880085263603e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.174159049987793 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06235372232922931\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05255847607831232\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████▎                          | 67/100 [08:35<04:14,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.7887347598000716e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.2129528522491455 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06311637764790029\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05325200306915785\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████                          | 68/100 [08:42<04:05,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.7462492188567172e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.142531871795654 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06330719007507707\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.05345280974375506\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▉                         | 69/100 [08:50<03:54,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.7361268227689187e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.3272435665130615 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06320383631669926\n",
      "val acc score is :0.9800237341772152\n",
      "test\n",
      "test loss score is :0.0534665210341677\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [08:58<03:48,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.672909000755135e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.004276990890503 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06340562141297339\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05365191938270222\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|█████████████████████████████████████████████████████████▌                       | 71/100 [09:05<03:36,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.6308892506500194e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 5.9795379638671875 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06359042255341243\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05378844654232807\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████▎                      | 72/100 [09:12<03:27,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.607909598791346e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.073239088058472 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.0630229823124675\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05342945237301632\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▏                     | 73/100 [09:19<03:20,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.5690365688299053e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.5688636302948 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06315951470032649\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.053510090161675614\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▉                     | 74/100 [09:27<03:15,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.5212703740356722e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 5.851105213165283 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06369136907608318\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05390366988074927\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▊                    | 75/100 [09:34<03:05,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.4701350742250985e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 5.922930002212524 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06330013477706083\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05365683761539303\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████▌                   | 76/100 [09:41<02:55,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.4559454400013589e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.343049049377441 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06339336976844366\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05385733307609308\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|██████████████████████████████████████████████████████████████▎                  | 77/100 [09:49<02:51,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.4248576638669206e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.733332633972168 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06423735230998917\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05446224573505692\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████████▏                 | 78/100 [09:57<02:48,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.4021972061897623e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.573103904724121 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06367974495208305\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.053990442908691455\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▉                 | 79/100 [10:05<02:41,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.3747030862587436e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.260871648788452 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06421661739888679\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05446398519715443\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▊                | 80/100 [10:13<02:33,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.3337837419023038e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.390991926193237 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.0643052813846551\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05458759206696053\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████▌               | 81/100 [10:21<02:26,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.3184909452825765e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.458559036254883 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06455370743831504\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05474986521349409\n",
      "test acc score is :0.9806170886075949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████▍              | 82/100 [10:28<02:19,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.2942095577825437e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.515283823013306 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06467592767802516\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05484798485865439\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|███████████████████████████████████████████████████████████████████▏             | 83/100 [10:36<02:12,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.2726046618642155e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.6098692417144775 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06451816080686645\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.054770351892113885\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████             | 84/100 [10:44<02:05,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.2342441340353518e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.348513841629028 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06466935722615641\n",
      "val acc score is :0.9799248417721519\n",
      "test\n",
      "test loss score is :0.05486123123058004\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▊            | 85/100 [10:52<01:56,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.2196207695843171e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.601705551147461 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06428756727060342\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.054664659811328495\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████▋           | 86/100 [11:00<01:49,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.2013058313924141e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.5810322761535645 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06437765883687968\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05477665115716586\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████████████▍          | 87/100 [11:08<01:42,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.1807518368885123e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.6181254386901855 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06445962765357019\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05479904131470147\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 88/100 [11:16<01:35,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.1579191263792936e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.525718450546265 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06457300251214966\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.054932408317269206\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████         | 89/100 [11:24<01:27,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.1510150381314418e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.650703430175781 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06456903830323027\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05495767341128876\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▉        | 90/100 [11:32<01:19,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.1174362615344385e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.636336326599121 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06469149327541915\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.055048021453867314\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▋       | 91/100 [11:40<01:11,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.1013502797583944e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.692647933959961 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06523038595505637\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05540636470433744\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████████████████████████████████████████▌      | 92/100 [11:48<01:03,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.0774752900346057e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.850815296173096 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.0648450061516176\n",
      "val acc score is :0.9797270569620253\n",
      "test\n",
      "test loss score is :0.05517951430731704\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████▎     | 93/100 [11:56<00:56,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.0587134294522741e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.571760654449463 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06548860175312697\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05565589357992253\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████████████████████████▏    | 94/100 [12:04<00:48,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.0423220264197715e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.745865345001221 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06503785133761933\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05532553145183593\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▉    | 95/100 [12:12<00:40,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.022432188459215e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.717489957809448 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06558008916053958\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05564851611154141\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████▊   | 96/100 [12:20<00:32,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :1.0086511880533642e-05\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.764218330383301 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06519250159321194\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05543361183546098\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████████████████▌  | 97/100 [12:28<00:24,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :9.955582047320227e-06\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.763607740402222 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06523709079633058\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.055502079652519604\n",
      "test acc score is :0.9808148734177216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████████████████████████████████████████████████████▍ | 98/100 [12:36<00:16,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :9.753931872792015e-06\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.534330129623413 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06589610477963187\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05598962460248052\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [12:44<00:08,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99\n",
      "train\n",
      "Using real-time data augmentation.\n",
      "train loss score is :9.696708010523825e-06\n",
      "train acc score is :0.9990409207161125\n",
      "It has been 6.554347515106201 seconds since the loop started\n",
      "test\n",
      "validation\n",
      "val loss score is :0.06601101487062144\n",
      "val acc score is :0.9798259493670886\n",
      "test\n",
      "test loss score is :0.05606305247760151\n",
      "test acc score is :0.9807159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [12:52<00:00,  8.03s/it]\n"
     ]
    }
   ],
   "source": [
    "input_tensors = [all_model[0].inputs[0], # input data\n",
    "                 all_model[0].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[0].targets[0], # labels\n",
    "                 K.learning_phase(), # train or test mode\n",
    "                 all_model[1].inputs[0], # input data\n",
    "                 all_model[1].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[1].targets[0], # labels\n",
    "                 all_model[2].inputs[0], # input data\n",
    "                 all_model[2].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[2].targets[0], # labels\n",
    "                ]\n",
    "\n",
    "\n",
    "minlos = K.argmin(losses)\n",
    "\n",
    "grr=[]\n",
    "for x in gr:\n",
    "    for y in x:\n",
    "        grr.append(y)\n",
    "\n",
    "upd_test= K.function(inputs=input_tensors, outputs=[ losses[0], losses[1], losses[2], minlos, prediction[0], prediction[1], prediction[2] ])\n",
    "\n",
    "\n",
    "grad_best=[]\n",
    "grad_non0 = []\n",
    "grad_non1 = []\n",
    "\n",
    "\n",
    "weig_best=[]\n",
    "weig_non0 = []\n",
    "weig_non1 = []\n",
    "\n",
    "xweig_best=[]\n",
    "xweig_non0 = []\n",
    "xweig_non1 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(gr[0])):\n",
    "    gr_ck=tf.concat([gr[0][i],gr[1][i], gr[2][i]],0)\n",
    "    newshape = (3, ) + (tuple(wr[0][i].shape))\n",
    "\n",
    "    \n",
    "    gr_ck2=tf.reshape(gr_ck, newshape)\n",
    "    \n",
    "    bb = gr_ck2[minlos]\n",
    "    grad_best.append(bb)\n",
    "    \n",
    "    nbb0 = gr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    nbb1 = gr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    nbc = tf.concat([nbb0,nbb1], 0)    \n",
    "    nbc = tf.reshape(nbc, (-1,))\n",
    "    newshape2 = (2, ) + (tuple(wr[0][i].shape))\n",
    "    \n",
    "    nbc2 = tf.reshape(nbc, newshape2) \n",
    "    nb0 = nbc2[0]\n",
    "    nb1 = nbc2[1]\n",
    "    grad_non0.append(nb0)\n",
    "    grad_non1.append(nb1)\n",
    "    \n",
    "\n",
    "    wr_ck=tf.concat([wr[0][i],wr[1][i], wr[2][i]],0)\n",
    "    \n",
    "    newshape = (3, ) + (tuple(wr[0][i].shape))\n",
    "    wr_ck2=tf.reshape(wr_ck, newshape) \n",
    "    bb2 = wr_ck2[minlos]\n",
    "    weig_best.append(bb2)\n",
    "    \n",
    "    #wb = wr_ck[minlos]\n",
    "    wnbb0 = wr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    wnbb1 = wr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    wnbc = tf.concat([wnbb0,wnbb1],0)    \n",
    "    wnbc = tf.reshape(wnbc, (-1,))\n",
    "    newshape2 = (2, ) + (tuple(wr[0][i].shape))\n",
    "    \n",
    "    wnbc2 =tf.reshape(wnbc, newshape2)\n",
    "    wnb0 = wnbc2[0]\n",
    "    wnb1 = wnbc2[1]\n",
    "    weig_non0.append(wnb0)\n",
    "    weig_non1.append(wnb1)\n",
    "    \n",
    "    if i<len(xwr[0]):\n",
    "        print (i)\n",
    "        xwr_ck=tf.concat([xwr[0][i],xwr[1][i], xwr[2][i]], 0)\n",
    "\n",
    "        newshape = (3, ) + (tuple(xwr[0][i].shape))\n",
    "        \n",
    "        xwr_ck2=tf.reshape(xwr_ck, newshape)  \n",
    "        xbb2 = xwr_ck2[minlos]\n",
    "        xweig_best.append(xbb2)\n",
    "\n",
    "        #wb = wr_ck[minlos]\n",
    "        xwnbb0 = xwr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "        xwnbb1 = xwr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "        xwnbc = tf.concat([xwnbb0,xwnbb1], 0)    \n",
    "        \n",
    "        xwnbc = tf.reshape(xwnbc, (-1,))\n",
    "        newshape2 = (2, ) + (tuple(xwr[0][i].shape))\n",
    "         \n",
    "        xwnbc2 = tf.reshape(xwnbc, newshape2) \n",
    "        xwnb0 = xwnbc2[0]\n",
    "        xwnb1 = xwnbc2[1]\n",
    "        xweig_non0.append(xwnb0)\n",
    "        xweig_non1.append(xwnb1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "los=tf.stack([losses[0], losses[1], losses[2]])\n",
    "\n",
    "newshape = (3, )\n",
    "los2=tf.reshape(los, newshape) \n",
    "losbest = los2[minlos]\n",
    "\n",
    "#wb = wr_ck[minlos]\n",
    "los_0 = los2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "los_1 = los2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "loswnbc = tf.concat([los_0,los_1],0)    \n",
    "loswnbc = tf.reshape(loswnbc,(-1,))\n",
    "newshape2 = (2, )\n",
    "\n",
    "loswnbc2 = tf.reshape(loswnbc, newshape2)\n",
    "losss0 = loswnbc2[0]\n",
    "losss1 = loswnbc2[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mn0 = [tf.keras.backend.l2_normalize((best-nonbest)*(losbest-losss0)/ tf.reduce_sum(tf.pow((best-nonbest),2)+eps))  for best, nonbest in zip(weig_best, weig_non0)]\n",
    "\n",
    "mn1 = [tf.keras.backend.l2_normalize((best-nonbest)*(losbest-losss1)/ tf.reduce_sum(tf.pow((best-nonbest),2)+eps))  for best, nonbest in zip(weig_best, weig_non1)]\n",
    "\n",
    "\n",
    "\n",
    "nCom0 = [non- lr3* grad - lr2* mn for mn, grad, non in zip(mn0,grad_non0, weig_non0 )]\n",
    "\n",
    "nCom1 = [non- lr3* grad - lr2 * mn for mn, grad, non in zip(mn1,grad_non1, weig_non1 )]\n",
    "\n",
    "xbest = [ -lr * nc + non for nc, non in zip(grad_best, weig_best)]\n",
    "\n",
    "\n",
    "upd2 = [\n",
    "    tf.assign(param_i, v)\n",
    "    for param_i, v in zip(wr[2], xbest)\n",
    "]\n",
    "\n",
    "upd2.extend(\n",
    "        [tf.assign(param_i, v)\n",
    "        for param_i, v in zip(xwr[2], xweig_best)]\n",
    "    )\n",
    "\n",
    "upd2.extend(\n",
    "        [tf.assign(param_i, v)\n",
    "        for param_i, v in zip(wr[1], nCom0)]\n",
    "    )\n",
    "upd2.extend(\n",
    "        [tf.assign(param_i, v)\n",
    "        for param_i, v in zip(xwr[1], xweig_non0)]\n",
    "    )\n",
    "upd2.extend(\n",
    "        [tf.assign(param_i, v)\n",
    "        for param_i, v in zip(wr[0], nCom1)]\n",
    "    )\n",
    "upd2.extend(\n",
    "        [tf.assign(param_i, v)\n",
    "        for param_i, v in zip(xwr[0], xweig_non1)]\n",
    "    )\n",
    "\n",
    "\n",
    "upd_bb2= K.function(inputs=input_tensors, outputs=[ losses[0], losses[1], losses[2], minlos, prediction[0], prediction[1], prediction[2] ], updates=upd2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lossepoch=[]\n",
    "lossepoch_test=[]\n",
    "lossx=[]\n",
    "acctra=[]\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "skip=[]\n",
    "\n",
    "\n",
    "loss_val=[]\n",
    "acc_val=[]\n",
    "lossepoch_val=[]\n",
    "\n",
    "   \n",
    "for f in tqdm(range(epochs)):\n",
    "    program_starts = time.time()\n",
    "    tr1=[]\n",
    "    tr2=[]\n",
    "    res1=[]\n",
    "    res2=[]\n",
    "    res3=[]\n",
    "    res4=[]\n",
    "    print('Epoch', f)\n",
    "    print ('train')\n",
    "    \n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in ImageDataGenerator().flow(x_train, y_train, batch_size=batch_size):\n",
    "        K.set_learning_phase(1)\n",
    "        inputs = [x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  1, # learning phase in Train mode\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                 ]\n",
    "        ll = upd_bb2(inputs)\n",
    "        yhat=ll[6]\n",
    "        #print (accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        #print (ll[:4])\n",
    "        lossepoch.append(ll[2])\n",
    "        tr1.append(ll[2])\n",
    "        tr2.append(accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        skip.append(ll[3])\n",
    "        batches += 1\n",
    "        if batches > len(x_train) / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    m=(len(x_train) / batch_size)-int((len(x_train) / batch_size))\n",
    "    tr1[-1]*=m\n",
    "    tr2[-1]*=m\n",
    "    lossx.append(np.mean(tr1))\n",
    "    acctra.append(np.mean(tr2))\n",
    "    print ('train loss score is :'+str(np.mean(tr1)))\n",
    "    print ('train acc score is :'+str(np.mean(tr2)))\n",
    "    now = time.time()\n",
    "    print(\"It has been {0} seconds since the loop started\".format(now - program_starts))\n",
    "    print ('test')\n",
    "    batchesx = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('validation')\n",
    "    batchesx = 0\n",
    "    for x_batch, y_batch in ImageDataGenerator().flow(x_val, y_val, batch_size=batch_size):\n",
    "        K.set_learning_phase(0)\n",
    "        inputs = [x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  1, # learning phase in VAl mode\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                 ]\n",
    "        ll = upd_test(inputs)\n",
    "        yhat=ll[6]\n",
    "        #print (accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        #print (ll[:3])\n",
    "        lossepoch_val.append(ll[2])\n",
    "        res3.append(ll[2])\n",
    "        res4.append(accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        batchesx += 1\n",
    "        if batchesx >= len(x_val) / batch_size:\n",
    "            break\n",
    "    m=(len(x_val) / batch_size)-int((len(x_val) / batch_size))\n",
    "    res3[-1]*=m\n",
    "    res4[-1]*=m\n",
    "    loss_val.append(np.mean(res3))\n",
    "    acc_val.append(np.mean(res4))\n",
    "    print ('val loss score is :'+str(np.mean(res3)))\n",
    "    print ('val acc score is :'+str(np.mean(res4)))\n",
    "    print ('test')\n",
    "    batchesx = 0\n",
    "    for x_batch, y_batch in ImageDataGenerator().flow(x_test, y_test, batch_size=batch_size):\n",
    "        K.set_learning_phase(0)\n",
    "        inputs = [x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  1, # learning phase in TEST mode\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                 ]\n",
    "        ll = upd_test(inputs)\n",
    "        yhat=ll[6]\n",
    "        #print (accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        #print (ll[:3])\n",
    "        lossepoch_test.append(ll[2])\n",
    "        res1.append(ll[2])\n",
    "        res2.append(accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        batchesx += 1\n",
    "        if batchesx >= len(x_test) / batch_size:\n",
    "            break\n",
    "    m=(len(x_test) / batch_size)-int((len(x_test) / batch_size))\n",
    "    res1[-1]*=m\n",
    "    res2[-1]*=m\n",
    "    loss_test.append(np.mean(res1))\n",
    "    acc_test.append(np.mean(res2))\n",
    "    print ('test loss score is :'+str(np.mean(res1)))\n",
    "    print ('test acc score is :'+str(np.mean(res2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9812104430379747 30\n",
      "0.9806170886075949 23\n",
      "0.030497980957609142 9\n",
      "0.03898478883638745 9\n"
     ]
    }
   ],
   "source": [
    "print (np.max(acc_test), np.argmax(acc_test))\n",
    "print (np.max(acc_val), np.argmax(acc_val))\n",
    "print (np.min(loss_test), np.argmin(loss_test))\n",
    "print (np.min(loss_val), np.argmin(loss_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"CR2_EVGO3_Mnist_lossepoch.csv\", lossepoch, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"CR2_EVGO3_Mnist_lossepoch_test.csv\", lossepoch_test, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"CR2_EVGO3_Mnist_loss_tra.csv\", lossx, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"CR2_EVGO3_Mnist_skip.csv\", skip, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"CR2_EVGO3_Mnist_loss_test.csv\", loss_test, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"CR2_EVGO3_Mnist_acc_test.csv\", acc_test, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9\n",
      "229\n",
      "405\n",
      "418\n",
      "439\n",
      "440\n",
      "453\n",
      "454\n",
      "461\n",
      "462\n",
      "475\n",
      "516\n",
      "521\n",
      "540\n",
      "563\n",
      "592\n",
      "613\n",
      "634\n",
      "749\n",
      "780\n",
      "785\n",
      "786\n",
      "789\n",
      "797\n",
      "798\n",
      "810\n",
      "815\n",
      "822\n",
      "823\n",
      "828\n",
      "829\n",
      "832\n",
      "833\n",
      "836\n",
      "837\n",
      "838\n",
      "841\n",
      "846\n",
      "851\n",
      "858\n",
      "865\n",
      "877\n",
      "878\n",
      "879\n",
      "884\n",
      "887\n",
      "890\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "909\n",
      "914\n",
      "917\n",
      "922\n",
      "929\n",
      "930\n",
      "940\n",
      "941\n",
      "945\n",
      "972\n",
      "975\n",
      "976\n",
      "977\n",
      "980\n",
      "983\n",
      "984\n",
      "985\n",
      "988\n",
      "994\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1008\n",
      "1010\n",
      "1012\n",
      "1021\n",
      "1022\n",
      "1027\n",
      "1030\n",
      "1037\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1062\n",
      "1063\n",
      "1065\n",
      "1068\n",
      "1070\n",
      "1075\n",
      "1078\n",
      "1085\n",
      "1095\n",
      "1096\n",
      "1101\n",
      "1106\n",
      "1107\n",
      "1109\n",
      "1116\n",
      "1117\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1124\n",
      "1126\n",
      "1131\n",
      "1132\n",
      "1138\n",
      "1139\n",
      "1142\n",
      "1143\n",
      "1145\n",
      "1146\n",
      "1150\n",
      "1151\n",
      "1159\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1167\n",
      "1172\n",
      "1176\n",
      "1177\n",
      "1180\n",
      "1182\n",
      "1189\n",
      "1190\n",
      "1193\n",
      "1197\n",
      "1198\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1207\n",
      "1208\n",
      "1210\n",
      "1223\n",
      "1224\n",
      "1227\n",
      "1231\n",
      "1233\n",
      "1239\n",
      "1241\n",
      "1242\n",
      "1245\n",
      "1250\n",
      "1252\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1260\n",
      "1262\n",
      "1264\n",
      "1266\n",
      "1267\n",
      "1274\n",
      "1276\n",
      "1282\n",
      "1283\n",
      "1293\n",
      "1297\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1306\n",
      "1309\n",
      "1311\n",
      "1314\n",
      "1318\n",
      "1320\n",
      "1321\n",
      "1323\n",
      "1329\n",
      "1336\n",
      "1342\n",
      "1348\n",
      "1349\n",
      "1365\n",
      "1370\n",
      "1371\n",
      "1375\n",
      "1384\n",
      "1387\n",
      "1393\n",
      "1400\n",
      "1404\n",
      "1407\n",
      "1410\n",
      "1411\n",
      "1416\n",
      "1420\n",
      "1422\n",
      "1430\n",
      "1431\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1445\n",
      "1446\n",
      "1448\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1464\n",
      "1465\n",
      "1471\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1480\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1489\n",
      "1494\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1504\n",
      "1507\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1522\n",
      "1530\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1542\n",
      "1544\n",
      "1545\n",
      "1548\n",
      "1550\n",
      "1557\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1566\n",
      "1567\n",
      "1569\n",
      "1575\n",
      "1577\n",
      "1581\n",
      "1582\n",
      "1594\n",
      "1597\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1614\n",
      "1615\n",
      "1617\n",
      "1619\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1626\n",
      "1628\n",
      "1630\n",
      "1631\n",
      "1634\n",
      "1637\n",
      "1676\n",
      "1683\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1695\n",
      "1698\n",
      "1699\n",
      "1702\n",
      "1717\n",
      "1734\n",
      "1737\n",
      "1742\n",
      "1761\n",
      "1762\n",
      "1769\n",
      "1770\n",
      "1777\n",
      "1778\n",
      "1781\n",
      "1784\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1810\n",
      "1813\n",
      "1818\n",
      "1825\n",
      "1826\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1846\n",
      "1849\n",
      "1850\n",
      "1857\n",
      "1860\n",
      "1861\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1871\n",
      "1872\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1890\n",
      "1891\n",
      "1894\n",
      "1896\n",
      "1898\n",
      "1901\n",
      "1902\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1916\n",
      "1923\n",
      "1932\n",
      "1936\n",
      "1939\n",
      "1941\n",
      "1942\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1956\n",
      "1963\n",
      "1965\n",
      "1971\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1986\n",
      "1988\n",
      "1990\n",
      "1991\n",
      "1993\n",
      "1995\n",
      "1998\n",
      "1999\n",
      "2005\n",
      "2011\n",
      "2012\n",
      "2015\n",
      "2021\n",
      "2022\n",
      "2024\n",
      "2031\n",
      "2033\n",
      "2035\n",
      "2039\n",
      "2041\n",
      "2044\n",
      "2048\n",
      "2052\n",
      "2058\n",
      "2060\n",
      "2062\n",
      "2066\n",
      "2067\n",
      "2069\n",
      "2071\n",
      "2072\n",
      "2078\n",
      "2081\n",
      "2085\n",
      "2087\n",
      "2089\n",
      "2097\n",
      "2098\n",
      "2100\n",
      "2103\n",
      "2111\n",
      "2117\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2126\n",
      "2131\n",
      "2133\n",
      "2138\n",
      "2139\n",
      "2145\n",
      "2149\n",
      "2150\n",
      "2152\n",
      "2156\n",
      "2158\n",
      "2162\n",
      "2168\n",
      "2169\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2184\n",
      "2185\n",
      "2190\n",
      "2194\n",
      "2195\n",
      "2201\n",
      "2210\n",
      "2212\n",
      "2216\n",
      "2217\n",
      "2223\n",
      "2224\n",
      "2230\n",
      "2231\n",
      "2236\n",
      "2239\n",
      "2251\n",
      "2258\n",
      "2263\n",
      "2271\n",
      "2275\n",
      "2283\n",
      "2284\n",
      "2286\n",
      "2292\n",
      "2296\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2312\n",
      "2320\n",
      "2321\n",
      "2323\n",
      "2325\n",
      "2327\n",
      "2331\n",
      "2332\n",
      "2334\n",
      "2339\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2351\n",
      "2352\n",
      "2358\n",
      "2363\n",
      "2365\n",
      "2368\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2374\n",
      "2379\n",
      "2381\n",
      "2395\n",
      "2399\n",
      "2405\n",
      "2407\n",
      "2409\n",
      "2415\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2421\n",
      "2430\n",
      "2435\n",
      "2444\n",
      "2447\n",
      "2452\n",
      "2460\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2476\n",
      "2485\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2497\n",
      "2498\n",
      "2500\n",
      "2506\n",
      "2518\n",
      "2522\n",
      "2528\n",
      "2531\n",
      "2533\n",
      "2544\n",
      "2545\n",
      "2547\n",
      "2548\n",
      "2556\n",
      "2559\n",
      "2560\n",
      "2563\n",
      "2564\n",
      "2572\n",
      "2574\n",
      "2575\n",
      "2585\n",
      "2588\n",
      "2595\n",
      "2600\n",
      "2603\n",
      "2606\n",
      "2607\n",
      "2609\n",
      "2622\n",
      "2626\n",
      "2631\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2648\n",
      "2655\n",
      "2660\n",
      "2670\n",
      "2671\n",
      "2673\n",
      "2675\n",
      "2677\n",
      "2678\n",
      "2684\n",
      "2685\n",
      "2688\n",
      "2691\n",
      "2697\n",
      "2701\n",
      "2702\n",
      "2705\n",
      "2715\n",
      "2722\n",
      "2723\n",
      "2726\n",
      "2728\n",
      "2731\n",
      "2738\n",
      "2741\n",
      "2744\n",
      "2745\n",
      "2750\n",
      "2753\n",
      "2756\n",
      "2757\n",
      "2760\n",
      "2775\n",
      "2777\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2786\n",
      "2794\n",
      "2796\n",
      "2797\n",
      "2801\n",
      "2802\n",
      "2804\n",
      "2806\n",
      "2811\n",
      "2812\n",
      "2816\n",
      "2817\n",
      "2820\n",
      "2822\n",
      "2837\n",
      "2842\n",
      "2844\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2855\n",
      "2856\n",
      "2860\n",
      "2869\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2879\n",
      "2883\n",
      "2888\n",
      "2890\n",
      "2892\n",
      "2893\n",
      "2897\n",
      "2900\n",
      "2904\n",
      "2906\n",
      "2911\n",
      "2924\n",
      "2926\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2934\n",
      "2937\n",
      "2942\n",
      "2945\n",
      "2946\n",
      "2949\n",
      "2950\n",
      "2956\n",
      "2960\n",
      "2967\n",
      "2968\n",
      "2971\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2990\n",
      "2991\n",
      "2996\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3004\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3025\n",
      "3030\n",
      "3035\n",
      "3038\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3052\n",
      "3054\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3066\n",
      "3067\n",
      "3071\n",
      "3073\n",
      "3081\n",
      "3084\n",
      "3092\n",
      "3096\n",
      "3097\n",
      "3100\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3132\n",
      "3144\n",
      "3147\n",
      "3150\n",
      "3151\n",
      "3154\n",
      "3155\n",
      "3167\n",
      "3168\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3180\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3195\n",
      "3198\n",
      "3199\n",
      "3201\n",
      "3206\n",
      "3216\n",
      "3217\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3238\n",
      "3240\n",
      "3241\n",
      "3247\n",
      "3251\n",
      "3252\n",
      "3256\n",
      "3261\n",
      "3262\n",
      "3274\n",
      "3275\n",
      "3289\n",
      "3293\n",
      "3294\n",
      "3297\n",
      "3298\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3305\n",
      "3306\n",
      "3311\n",
      "3314\n",
      "3316\n",
      "3319\n",
      "3320\n",
      "3322\n",
      "3324\n",
      "3325\n",
      "3327\n",
      "3329\n",
      "3331\n",
      "3336\n",
      "3339\n",
      "3340\n",
      "3345\n",
      "3350\n",
      "3351\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3358\n",
      "3360\n",
      "3361\n",
      "3377\n",
      "3378\n",
      "3382\n",
      "3383\n",
      "3388\n",
      "3394\n",
      "3399\n",
      "3402\n",
      "3405\n",
      "3406\n",
      "3408\n",
      "3409\n",
      "3411\n",
      "3415\n",
      "3419\n",
      "3420\n",
      "3425\n",
      "3426\n",
      "3429\n",
      "3432\n",
      "3442\n",
      "3447\n",
      "3450\n",
      "3455\n",
      "3456\n",
      "3459\n",
      "3475\n",
      "3481\n",
      "3487\n",
      "3489\n",
      "3490\n",
      "3492\n",
      "3495\n",
      "3498\n",
      "3499\n",
      "3501\n",
      "3503\n",
      "3505\n",
      "3506\n",
      "3511\n",
      "3512\n",
      "3517\n",
      "3524\n",
      "3525\n",
      "3528\n",
      "3533\n",
      "3534\n",
      "3540\n",
      "3545\n",
      "3546\n",
      "3550\n",
      "3555\n",
      "3559\n",
      "3565\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3582\n",
      "3588\n",
      "3590\n",
      "3591\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3603\n",
      "3604\n",
      "3616\n",
      "3619\n",
      "3620\n",
      "3622\n",
      "3623\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3634\n",
      "3635\n",
      "3640\n",
      "3643\n",
      "3645\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3655\n",
      "3657\n",
      "3662\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3677\n",
      "3679\n",
      "3683\n",
      "3684\n",
      "3687\n",
      "3688\n",
      "3690\n",
      "3693\n",
      "3700\n",
      "3701\n",
      "3704\n",
      "3705\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3726\n",
      "3727\n",
      "3729\n",
      "3730\n",
      "3732\n",
      "3737\n",
      "3739\n",
      "3740\n",
      "3742\n",
      "3746\n",
      "3752\n",
      "3754\n",
      "3760\n",
      "3769\n",
      "3770\n",
      "3773\n",
      "3774\n",
      "3777\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3797\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3808\n",
      "3810\n",
      "3811\n",
      "3814\n",
      "3815\n",
      "3821\n",
      "3823\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3836\n",
      "3840\n",
      "3845\n",
      "3846\n",
      "3848\n",
      "3849\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3862\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3872\n",
      "3874\n",
      "3876\n",
      "3877\n",
      "3879\n",
      "3880\n",
      "3882\n",
      "3884\n",
      "3885\n",
      "3891\n",
      "3892\n",
      "3895\n",
      "3899\n",
      "3900\n",
      "3910\n",
      "3911\n",
      "3913\n",
      "3917\n",
      "3919\n",
      "3920\n",
      "3930\n",
      "3932\n",
      "3935\n",
      "3939\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3951\n",
      "3952\n",
      "3955\n",
      "3965\n",
      "3970\n",
      "3971\n",
      "3979\n",
      "3980\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3990\n",
      "3998\n",
      "4000\n",
      "4001\n",
      "4004\n",
      "4007\n",
      "4012\n",
      "4013\n",
      "4018\n",
      "4019\n",
      "4023\n",
      "4024\n",
      "4033\n",
      "4038\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4051\n",
      "4052\n",
      "4054\n",
      "4056\n",
      "4059\n",
      "4062\n",
      "4063\n",
      "4069\n",
      "4074\n",
      "4079\n",
      "4080\n",
      "4082\n",
      "4094\n",
      "4095\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4103\n",
      "4106\n",
      "4108\n",
      "4116\n",
      "4125\n",
      "4128\n",
      "4130\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4139\n",
      "4143\n",
      "4147\n",
      "4152\n",
      "4153\n",
      "4155\n",
      "4156\n",
      "4158\n",
      "4159\n",
      "4162\n",
      "4163\n",
      "4173\n",
      "4178\n",
      "4181\n",
      "4182\n",
      "4184\n",
      "4186\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4200\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4210\n",
      "4212\n",
      "4213\n",
      "4218\n",
      "4225\n",
      "4228\n",
      "4232\n",
      "4233\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4246\n",
      "4247\n",
      "4251\n",
      "4254\n",
      "4258\n",
      "4259\n",
      "4265\n",
      "4266\n",
      "4268\n",
      "4270\n",
      "4273\n",
      "4274\n",
      "4279\n",
      "4280\n",
      "4282\n",
      "4286\n",
      "4288\n",
      "4291\n",
      "4296\n",
      "4306\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4314\n",
      "4315\n",
      "4319\n",
      "4326\n",
      "4330\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4338\n",
      "4341\n",
      "4346\n",
      "4351\n",
      "4356\n",
      "4358\n",
      "4365\n",
      "4371\n",
      "4378\n",
      "4379\n",
      "4386\n",
      "4387\n",
      "4391\n",
      "4394\n",
      "4395\n",
      "4397\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4405\n",
      "4409\n",
      "4410\n",
      "4415\n",
      "4417\n",
      "4418\n",
      "4421\n",
      "4422\n",
      "4425\n",
      "4426\n",
      "4430\n",
      "4431\n",
      "4433\n",
      "4439\n",
      "4440\n",
      "4442\n",
      "4446\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4460\n",
      "4461\n",
      "4465\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4476\n",
      "4479\n",
      "4480\n",
      "4483\n",
      "4484\n",
      "4487\n",
      "4490\n",
      "4491\n",
      "4493\n",
      "4496\n",
      "4505\n",
      "4507\n",
      "4513\n",
      "4515\n",
      "4516\n",
      "4519\n",
      "4521\n",
      "4534\n",
      "4535\n",
      "4537\n",
      "4538\n",
      "4540\n",
      "4544\n",
      "4545\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4556\n",
      "4558\n",
      "4565\n",
      "4568\n",
      "4570\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4577\n",
      "4585\n",
      "4587\n",
      "4589\n",
      "4594\n",
      "4595\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4608\n",
      "4612\n",
      "4618\n",
      "4625\n",
      "4629\n",
      "4630\n",
      "4639\n",
      "4643\n",
      "4644\n",
      "4646\n",
      "4647\n",
      "4651\n",
      "4655\n",
      "4658\n",
      "4671\n",
      "4673\n",
      "4682\n",
      "4686\n",
      "4687\n",
      "4690\n",
      "4691\n",
      "4695\n",
      "4697\n",
      "4700\n",
      "4706\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4720\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4744\n",
      "4746\n",
      "4754\n",
      "4755\n",
      "4758\n",
      "4761\n",
      "4765\n",
      "4766\n",
      "4768\n",
      "4773\n",
      "4780\n",
      "4782\n",
      "4787\n",
      "4790\n",
      "4792\n",
      "4794\n",
      "4795\n",
      "4798\n",
      "4799\n",
      "4810\n",
      "4823\n",
      "4824\n",
      "4827\n",
      "4829\n",
      "4831\n",
      "4832\n",
      "4842\n",
      "4843\n",
      "4855\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4862\n",
      "4864\n",
      "4871\n",
      "4874\n",
      "4875\n",
      "4882\n",
      "4883\n",
      "4887\n",
      "4888\n",
      "4894\n",
      "4896\n",
      "4902\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4915\n",
      "4916\n",
      "4935\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4944\n",
      "4945\n",
      "4949\n",
      "4953\n",
      "4957\n",
      "4965\n",
      "4968\n",
      "4973\n",
      "4974\n",
      "4976\n",
      "4977\n",
      "4981\n",
      "4982\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4994\n",
      "4997\n",
      "4999\n",
      "5000\n",
      "5002\n",
      "5006\n",
      "5010\n",
      "5012\n",
      "5013\n",
      "5026\n",
      "5028\n",
      "5033\n",
      "5035\n",
      "5037\n",
      "5039\n",
      "5040\n",
      "5051\n",
      "5056\n",
      "5057\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5064\n",
      "5065\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5086\n",
      "5093\n",
      "5097\n",
      "5102\n",
      "5103\n",
      "5113\n",
      "5114\n",
      "5117\n",
      "5119\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5128\n",
      "5135\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5141\n",
      "5148\n",
      "5151\n",
      "5152\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5164\n",
      "5172\n",
      "5176\n",
      "5179\n",
      "5180\n",
      "5183\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5192\n",
      "5194\n",
      "5214\n",
      "5215\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5231\n",
      "5234\n",
      "5238\n",
      "5244\n",
      "5246\n",
      "5248\n",
      "5250\n",
      "5251\n",
      "5262\n",
      "5263\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5275\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5290\n",
      "5292\n",
      "5295\n",
      "5303\n",
      "5306\n",
      "5318\n",
      "5319\n",
      "5322\n",
      "5324\n",
      "5329\n",
      "5333\n",
      "5334\n",
      "5340\n",
      "5344\n",
      "5346\n",
      "5349\n",
      "5353\n",
      "5363\n",
      "5365\n",
      "5368\n",
      "5370\n",
      "5374\n",
      "5375\n",
      "5383\n",
      "5384\n",
      "5387\n",
      "5392\n",
      "5393\n",
      "5396\n",
      "5399\n",
      "5400\n",
      "5404\n",
      "5405\n",
      "5409\n",
      "5411\n",
      "5412\n",
      "5416\n",
      "5417\n",
      "5421\n",
      "5424\n",
      "5432\n",
      "5433\n",
      "5438\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5447\n",
      "5452\n",
      "5453\n",
      "5460\n",
      "5463\n",
      "5464\n",
      "5467\n",
      "5468\n",
      "5472\n",
      "5473\n",
      "5475\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5485\n",
      "5486\n",
      "5492\n",
      "5495\n",
      "5497\n",
      "5499\n",
      "5505\n",
      "5507\n",
      "5509\n",
      "5519\n",
      "5521\n",
      "5532\n",
      "5536\n",
      "5541\n",
      "5542\n",
      "5547\n",
      "5549\n",
      "5550\n",
      "5552\n",
      "5553\n",
      "5556\n",
      "5558\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5570\n",
      "5572\n",
      "5579\n",
      "5581\n",
      "5585\n",
      "5596\n",
      "5597\n",
      "5599\n",
      "5600\n",
      "5606\n",
      "5609\n",
      "5610\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5628\n",
      "5629\n",
      "5631\n",
      "5632\n",
      "5634\n",
      "5635\n",
      "5645\n",
      "5647\n",
      "5649\n",
      "5661\n",
      "5662\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5674\n",
      "5685\n",
      "5690\n",
      "5693\n",
      "5700\n",
      "5701\n",
      "5704\n",
      "5705\n",
      "5713\n",
      "5715\n",
      "5728\n",
      "5731\n",
      "5732\n",
      "5740\n",
      "5741\n",
      "5743\n",
      "5750\n",
      "5753\n",
      "5757\n",
      "5759\n",
      "5767\n",
      "5769\n",
      "5779\n",
      "5782\n",
      "5787\n",
      "5791\n",
      "5792\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5808\n",
      "5810\n",
      "5813\n",
      "5820\n",
      "5825\n",
      "5830\n",
      "5834\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5854\n",
      "5856\n",
      "5866\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5881\n",
      "5883\n",
      "5886\n",
      "5887\n",
      "5896\n",
      "5905\n",
      "5907\n",
      "5909\n",
      "5910\n",
      "5922\n",
      "5924\n",
      "5937\n",
      "5942\n",
      "5943\n",
      "5945\n",
      "5946\n",
      "5948\n",
      "5949\n",
      "5951\n",
      "5953\n",
      "5962\n",
      "5978\n",
      "5981\n",
      "5982\n",
      "5985\n",
      "5987\n",
      "5992\n",
      "6000\n",
      "6001\n",
      "6005\n",
      "6007\n",
      "6008\n",
      "6010\n",
      "6013\n",
      "6014\n",
      "6017\n",
      "6018\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6025\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6038\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6056\n",
      "6060\n",
      "6061\n",
      "6064\n",
      "6065\n",
      "6068\n",
      "6069\n",
      "6073\n",
      "6075\n",
      "6077\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6086\n",
      "6089\n",
      "6094\n",
      "6102\n",
      "6109\n",
      "6115\n",
      "6117\n",
      "6126\n",
      "6127\n",
      "6130\n",
      "6132\n",
      "6133\n",
      "6136\n",
      "6137\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6143\n",
      "6144\n",
      "6146\n",
      "6151\n",
      "6153\n",
      "6158\n",
      "6159\n",
      "6162\n",
      "6163\n",
      "6166\n",
      "6167\n",
      "6170\n",
      "6171\n",
      "6176\n",
      "6180\n",
      "6182\n",
      "6183\n",
      "6192\n",
      "6193\n",
      "6195\n",
      "6196\n",
      "6202\n",
      "6203\n",
      "6208\n",
      "6210\n",
      "6211\n",
      "6213\n",
      "6214\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6230\n",
      "6232\n",
      "6233\n",
      "6235\n",
      "6238\n",
      "6241\n",
      "6244\n",
      "6249\n",
      "6250\n",
      "6254\n",
      "6257\n",
      "6262\n",
      "6265\n",
      "6267\n",
      "6273\n",
      "6274\n",
      "6278\n",
      "6279\n",
      "6287\n",
      "6294\n",
      "6304\n",
      "6306\n",
      "6307\n",
      "6309\n",
      "6311\n",
      "6317\n",
      "6320\n",
      "6323\n",
      "6324\n",
      "6331\n",
      "6339\n",
      "6340\n",
      "6342\n",
      "6343\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6354\n",
      "6355\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6372\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6395\n",
      "6400\n",
      "6401\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6410\n",
      "6415\n",
      "6416\n",
      "6420\n",
      "6422\n",
      "6425\n",
      "6432\n",
      "6434\n",
      "6435\n",
      "6437\n",
      "6438\n",
      "6440\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6456\n",
      "6457\n",
      "6461\n",
      "6464\n",
      "6465\n",
      "6467\n",
      "6469\n",
      "6470\n",
      "6475\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6484\n",
      "6485\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6495\n",
      "6496\n",
      "6498\n",
      "6499\n",
      "6501\n",
      "6502\n",
      "6505\n",
      "6510\n",
      "6513\n",
      "6514\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6525\n",
      "6527\n",
      "6531\n",
      "6537\n",
      "6539\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6548\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6555\n",
      "6564\n",
      "6566\n",
      "6572\n",
      "6573\n",
      "6577\n",
      "6587\n",
      "6588\n",
      "6590\n",
      "6593\n",
      "6598\n",
      "6600\n",
      "6605\n",
      "6610\n",
      "6611\n",
      "6622\n",
      "6623\n",
      "6627\n",
      "6628\n",
      "6632\n",
      "6633\n",
      "6636\n",
      "6638\n",
      "6640\n",
      "6644\n",
      "6649\n",
      "6651\n",
      "6655\n",
      "6656\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6669\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6679\n",
      "6680\n",
      "6685\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6695\n",
      "6697\n",
      "6700\n",
      "6704\n",
      "6713\n",
      "6715\n",
      "6716\n",
      "6719\n",
      "6732\n",
      "6734\n",
      "6736\n",
      "6737\n",
      "6742\n",
      "6746\n",
      "6747\n",
      "6753\n",
      "6764\n",
      "6776\n",
      "6778\n",
      "6782\n",
      "6788\n",
      "6792\n",
      "6799\n",
      "6819\n",
      "6824\n",
      "6826\n",
      "6829\n",
      "6831\n",
      "6846\n",
      "6847\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6853\n",
      "6857\n",
      "6859\n",
      "6863\n",
      "6865\n",
      "6866\n",
      "6868\n",
      "6879\n",
      "6885\n",
      "6893\n",
      "6897\n",
      "6900\n",
      "6902\n",
      "6908\n",
      "6912\n",
      "6918\n",
      "6920\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6933\n",
      "6934\n",
      "6938\n",
      "6940\n",
      "6941\n",
      "6943\n",
      "6945\n",
      "6946\n",
      "6947\n",
      "6948\n",
      "6949\n",
      "6951\n",
      "6952\n",
      "6955\n",
      "6956\n",
      "6963\n",
      "6964\n",
      "6968\n",
      "6977\n",
      "6978\n",
      "6979\n",
      "6982\n",
      "6985\n",
      "6986\n",
      "6994\n",
      "7008\n",
      "7012\n",
      "7013\n",
      "7015\n",
      "7016\n",
      "7017\n",
      "7021\n",
      "7022\n",
      "7024\n",
      "7026\n",
      "7030\n",
      "7031\n",
      "7041\n",
      "7042\n",
      "7049\n",
      "7050\n",
      "7051\n",
      "7052\n",
      "7055\n",
      "7056\n",
      "7063\n",
      "7064\n",
      "7065\n",
      "7075\n",
      "7076\n",
      "7077\n",
      "7078\n",
      "7084\n",
      "7087\n",
      "7089\n",
      "7090\n",
      "7091\n",
      "7095\n",
      "7096\n",
      "7097\n",
      "7098\n",
      "7099\n",
      "7100\n",
      "7105\n",
      "7107\n",
      "7110\n",
      "7111\n",
      "7113\n",
      "7114\n",
      "7116\n",
      "7125\n",
      "7133\n",
      "7134\n",
      "7135\n",
      "7137\n",
      "7139\n",
      "7142\n",
      "7143\n",
      "7145\n",
      "7153\n",
      "7157\n",
      "7159\n",
      "7160\n",
      "7166\n",
      "7173\n",
      "7179\n",
      "7180\n",
      "7181\n",
      "7183\n",
      "7185\n",
      "7186\n",
      "7190\n",
      "7195\n",
      "7196\n",
      "7199\n",
      "7201\n",
      "7202\n",
      "7203\n",
      "7205\n",
      "7211\n",
      "7213\n",
      "7214\n",
      "7215\n",
      "7219\n",
      "7224\n",
      "7226\n",
      "7229\n",
      "7232\n",
      "7233\n",
      "7234\n",
      "7241\n",
      "7243\n",
      "7246\n",
      "7247\n",
      "7249\n",
      "7255\n",
      "7257\n",
      "7259\n",
      "7260\n",
      "7261\n",
      "7264\n",
      "7265\n",
      "7266\n",
      "7268\n",
      "7272\n",
      "7273\n",
      "7277\n",
      "7278\n",
      "7279\n",
      "7282\n",
      "7284\n",
      "7286\n",
      "7288\n",
      "7292\n",
      "7296\n",
      "7297\n",
      "7300\n",
      "7303\n",
      "7311\n",
      "7314\n",
      "7316\n",
      "7318\n",
      "7319\n",
      "7322\n",
      "7323\n",
      "7325\n",
      "7326\n",
      "7327\n",
      "7328\n",
      "7331\n",
      "7332\n",
      "7339\n",
      "7340\n",
      "7341\n",
      "7342\n",
      "7344\n",
      "7345\n",
      "7354\n",
      "7363\n",
      "7367\n",
      "7377\n",
      "7389\n",
      "7390\n",
      "7395\n",
      "7397\n",
      "7398\n",
      "7401\n",
      "7409\n",
      "7410\n",
      "7412"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6f262da22770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(skip)):\n",
    "    if skip[i]==0:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "446\n",
      "460\n",
      "464\n",
      "474\n",
      "527\n",
      "556\n",
      "565\n",
      "569\n",
      "573\n",
      "583\n",
      "587\n",
      "600\n",
      "608\n",
      "615\n",
      "782\n",
      "788\n",
      "791\n",
      "793\n",
      "814\n",
      "821\n",
      "827\n",
      "831\n",
      "845\n",
      "850\n",
      "853\n",
      "862\n",
      "863\n",
      "866\n",
      "870\n",
      "886\n",
      "913\n",
      "916\n",
      "919\n",
      "921\n",
      "928\n",
      "944\n",
      "949\n",
      "951\n",
      "967\n",
      "971\n",
      "974\n",
      "987\n",
      "989\n",
      "990\n",
      "1000\n",
      "1002\n",
      "1007\n",
      "1011\n",
      "1013\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1023\n",
      "1026\n",
      "1029\n",
      "1033\n",
      "1036\n",
      "1051\n",
      "1056\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1064\n",
      "1066\n",
      "1067\n",
      "1073\n",
      "1074\n",
      "1086\n",
      "1087\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1097\n",
      "1100\n",
      "1103\n",
      "1105\n",
      "1115\n",
      "1118\n",
      "1129\n",
      "1134\n",
      "1158\n",
      "1165\n",
      "1166\n",
      "1173\n",
      "1174\n",
      "1178\n",
      "1179\n",
      "1181\n",
      "1195\n",
      "1196\n",
      "1199\n",
      "1200\n",
      "1205\n",
      "1206\n",
      "1209\n",
      "1236\n",
      "1249\n",
      "1251\n",
      "1253\n",
      "1258\n",
      "1259\n",
      "1263\n",
      "1265\n",
      "1268\n",
      "1269\n",
      "1275\n",
      "1277\n",
      "1278\n",
      "1295\n",
      "1305\n",
      "1307\n",
      "1310\n",
      "1312\n",
      "1315\n",
      "1317\n",
      "1324\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1331\n",
      "1332\n",
      "1334\n",
      "1335\n",
      "1338\n",
      "1339\n",
      "1343\n",
      "1344\n",
      "1350\n",
      "1352\n",
      "1363\n",
      "1367\n",
      "1368\n",
      "1373\n",
      "1374\n",
      "1381\n",
      "1386\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1403\n",
      "1406\n",
      "1408\n",
      "1412\n",
      "1417\n",
      "1423\n",
      "1426\n",
      "1427\n",
      "1429\n",
      "1433\n",
      "1435\n",
      "1449\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1460\n",
      "1470\n",
      "1473\n",
      "1478\n",
      "1486\n",
      "1488\n",
      "1490\n",
      "1502\n",
      "1519\n",
      "1520\n",
      "1526\n",
      "1528\n",
      "1535\n",
      "1543\n",
      "1547\n",
      "1551\n",
      "1555\n",
      "1563\n",
      "1568\n",
      "1570\n",
      "1572\n",
      "1576\n",
      "1579\n",
      "1580\n",
      "1583\n",
      "1584\n",
      "1587\n",
      "1588\n",
      "1591\n",
      "1593\n",
      "1605\n",
      "1608\n",
      "1620\n",
      "1625\n",
      "1632\n",
      "1633\n",
      "1653\n",
      "1655\n",
      "1661\n",
      "1663\n",
      "1665\n",
      "1671\n",
      "1673\n",
      "1682\n",
      "1685\n",
      "1697\n",
      "1704\n",
      "1706\n",
      "1708\n",
      "1710\n",
      "1716\n",
      "1736\n",
      "1741\n",
      "1748\n",
      "1764\n",
      "1766\n",
      "1774\n",
      "1776\n",
      "1788\n",
      "1796\n",
      "1800\n",
      "1805\n",
      "1809\n",
      "1815\n",
      "1820\n",
      "1828\n",
      "1830\n",
      "1832\n",
      "1834\n",
      "1841\n",
      "1843\n",
      "1854\n",
      "1859\n",
      "1874\n",
      "1878\n",
      "1880\n",
      "1893\n",
      "1895\n",
      "1913\n",
      "1918\n",
      "1925\n",
      "1927\n",
      "1934\n",
      "1935\n",
      "1937\n",
      "1938\n",
      "1940\n",
      "1948\n",
      "1958\n",
      "1964\n",
      "1970\n",
      "1973\n",
      "1978\n",
      "1979\n",
      "1983\n",
      "1984\n",
      "1987\n",
      "1992\n",
      "1996\n",
      "2006\n",
      "2007\n",
      "2014\n",
      "2017\n",
      "2028\n",
      "2032\n",
      "2034\n",
      "2040\n",
      "2042\n",
      "2045\n",
      "2047\n",
      "2053\n",
      "2057\n",
      "2070\n",
      "2077\n",
      "2082\n",
      "2084\n",
      "2090\n",
      "2091\n",
      "2093\n",
      "2094\n",
      "2099\n",
      "2101\n",
      "2105\n",
      "2106\n",
      "2108\n",
      "2114\n",
      "2120\n",
      "2124\n",
      "2125\n",
      "2127\n",
      "2129\n",
      "2136\n",
      "2141\n",
      "2142\n",
      "2144\n",
      "2151\n",
      "2157\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2172\n",
      "2177\n",
      "2191\n",
      "2193\n",
      "2197\n",
      "2209\n",
      "2214\n",
      "2215\n",
      "2222\n",
      "2229\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2238\n",
      "2240\n",
      "2242\n",
      "2249\n",
      "2259\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2270\n",
      "2273\n",
      "2278\n",
      "2279\n",
      "2281\n",
      "2282\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2301\n",
      "2307\n",
      "2308\n",
      "2311\n",
      "2313\n",
      "2315\n",
      "2317\n",
      "2322\n",
      "2328\n",
      "2330\n",
      "2340\n",
      "2347\n",
      "2350\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2359\n",
      "2360\n",
      "2362\n",
      "2366\n",
      "2367\n",
      "2369\n",
      "2380\n",
      "2382\n",
      "2383\n",
      "2386\n",
      "2393\n",
      "2396\n",
      "2398\n",
      "2400\n",
      "2408\n",
      "2410\n",
      "2420\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2428\n",
      "2429\n",
      "2431\n",
      "2433\n",
      "2434\n",
      "2439\n",
      "2441\n",
      "2445\n",
      "2449\n",
      "2451\n",
      "2454\n",
      "2456\n",
      "2458\n",
      "2462\n",
      "2469\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2482\n",
      "2483\n",
      "2486\n",
      "2487\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2501\n",
      "2504\n",
      "2507\n",
      "2509\n",
      "2511\n",
      "2513\n",
      "2517\n",
      "2519\n",
      "2520\n",
      "2523\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2530\n",
      "2532\n",
      "2538\n",
      "2539\n",
      "2546\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2555\n",
      "2562\n",
      "2566\n",
      "2570\n",
      "2571\n",
      "2573\n",
      "2576\n",
      "2578\n",
      "2579\n",
      "2581\n",
      "2589\n",
      "2599\n",
      "2605\n",
      "2608\n",
      "2610\n",
      "2612\n",
      "2614\n",
      "2615\n",
      "2621\n",
      "2625\n",
      "2628\n",
      "2629\n",
      "2633\n",
      "2635\n",
      "2640\n",
      "2641\n",
      "2646\n",
      "2654\n",
      "2659\n",
      "2661\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2668\n",
      "2669\n",
      "2672\n",
      "2674\n",
      "2679\n",
      "2686\n",
      "2687\n",
      "2689\n",
      "2690\n",
      "2694\n",
      "2699\n",
      "2703\n",
      "2704\n",
      "2713\n",
      "2717\n",
      "2718\n",
      "2721\n",
      "2740\n",
      "2742\n",
      "2749\n",
      "2751\n",
      "2752\n",
      "2758\n",
      "2761\n",
      "2764\n",
      "2767\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2773\n",
      "2774\n",
      "2776\n",
      "2779\n",
      "2785\n",
      "2787\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2798\n",
      "2799\n",
      "2803\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2815\n",
      "2819\n",
      "2821\n",
      "2823\n",
      "2835\n",
      "2838\n",
      "2839\n",
      "2841\n",
      "2845\n",
      "2846\n",
      "2862\n",
      "2863\n",
      "2866\n",
      "2868\n",
      "2870\n",
      "2873\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2895\n",
      "2896\n",
      "2898\n",
      "2899\n",
      "2901\n",
      "2902\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2916\n",
      "2919\n",
      "2921\n",
      "2925\n",
      "2927\n",
      "2932\n",
      "2935\n",
      "2936\n",
      "2941\n",
      "2948\n",
      "2955\n",
      "2958\n",
      "2959\n",
      "2962\n",
      "2969\n",
      "2976\n",
      "2978\n",
      "2994\n",
      "2995\n",
      "3003\n",
      "3013\n",
      "3014\n",
      "3016\n",
      "3026\n",
      "3027\n",
      "3034\n",
      "3036\n",
      "3037\n",
      "3039\n",
      "3042\n",
      "3044\n",
      "3049\n",
      "3055\n",
      "3070\n",
      "3078\n",
      "3082\n",
      "3083\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3089\n",
      "3091\n",
      "3093\n",
      "3098\n",
      "3101\n",
      "3110\n",
      "3114\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3122\n",
      "3123\n",
      "3126\n",
      "3128\n",
      "3131\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3139\n",
      "3141\n",
      "3143\n",
      "3145\n",
      "3149\n",
      "3153\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3162\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3179\n",
      "3181\n",
      "3202\n",
      "3203\n",
      "3205\n",
      "3209\n",
      "3211\n",
      "3214\n",
      "3218\n",
      "3221\n",
      "3226\n",
      "3246\n",
      "3250\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3258\n",
      "3260\n",
      "3264\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3276\n",
      "3277\n",
      "3279\n",
      "3282\n",
      "3284\n",
      "3288\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3299\n",
      "3303\n",
      "3309\n",
      "3313\n",
      "3315\n",
      "3317\n",
      "3318\n",
      "3328\n",
      "3335\n",
      "3347\n",
      "3352\n",
      "3353\n",
      "3357\n",
      "3363\n",
      "3364\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3380\n",
      "3387\n",
      "3390\n",
      "3391\n",
      "3393\n",
      "3400\n",
      "3410\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3422\n",
      "3431\n",
      "3436\n",
      "3438\n",
      "3439\n",
      "3441\n",
      "3446\n",
      "3458\n",
      "3460\n",
      "3462\n",
      "3465\n",
      "3469\n",
      "3471\n",
      "3477\n",
      "3482\n",
      "3483\n",
      "3488\n",
      "3491\n",
      "3493\n",
      "3494\n",
      "3496\n",
      "3497\n",
      "3500\n",
      "3502\n",
      "3507\n",
      "3509\n",
      "3518\n",
      "3521\n",
      "3529\n",
      "3530\n",
      "3544\n",
      "3547\n",
      "3548\n",
      "3553\n",
      "3556\n",
      "3560\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3567\n",
      "3577\n",
      "3580\n",
      "3584\n",
      "3587\n",
      "3592\n",
      "3593\n",
      "3600\n",
      "3605\n",
      "3606\n",
      "3614\n",
      "3615\n",
      "3617\n",
      "3625\n",
      "3632\n",
      "3633\n",
      "3636\n",
      "3641\n",
      "3642\n",
      "3646\n",
      "3661\n",
      "3663\n",
      "3664\n",
      "3666\n",
      "3671\n",
      "3674\n",
      "3675\n",
      "3680\n",
      "3681\n",
      "3689\n",
      "3699\n",
      "3702\n",
      "3707\n",
      "3723\n",
      "3725\n",
      "3734\n",
      "3735\n",
      "3738\n",
      "3744\n",
      "3747\n",
      "3748\n",
      "3751\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3762\n",
      "3763\n",
      "3766\n",
      "3767\n",
      "3771\n",
      "3775\n",
      "3776\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3790\n",
      "3792\n",
      "3795\n",
      "3796\n",
      "3798\n",
      "3807\n",
      "3818\n",
      "3819\n",
      "3822\n",
      "3831\n",
      "3835\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3850\n",
      "3860\n",
      "3861\n",
      "3868\n",
      "3873\n",
      "3875\n",
      "3881\n",
      "3890\n",
      "3893\n",
      "3898\n",
      "3901\n",
      "3902\n",
      "3904\n",
      "3906\n",
      "3908\n",
      "3912\n",
      "3916\n",
      "3918\n",
      "3921\n",
      "3925\n",
      "3928\n",
      "3929\n",
      "3931\n",
      "3934\n",
      "3937\n",
      "3940\n",
      "3941\n",
      "3945\n",
      "3950\n",
      "3954\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3963\n",
      "3967\n",
      "3982\n",
      "3983\n",
      "3997\n",
      "4003\n",
      "4006\n",
      "4020\n",
      "4040\n",
      "4042\n",
      "4049\n",
      "4050\n",
      "4053\n",
      "4057\n",
      "4070\n",
      "4072\n",
      "4073\n",
      "4075\n",
      "4076\n",
      "4081\n",
      "4083\n",
      "4085\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4096\n",
      "4102\n",
      "4104\n",
      "4112\n",
      "4113\n",
      "4115\n",
      "4117\n",
      "4118\n",
      "4121\n",
      "4122\n",
      "4124\n",
      "4127\n",
      "4129\n",
      "4132\n",
      "4138\n",
      "4140\n",
      "4145\n",
      "4150\n",
      "4151\n",
      "4154\n",
      "4157\n",
      "4160\n",
      "4164\n",
      "4165\n",
      "4167\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4175\n",
      "4187\n",
      "4194\n",
      "4198\n",
      "4201\n",
      "4209\n",
      "4214\n",
      "4217\n",
      "4219\n",
      "4229\n",
      "4231\n",
      "4235\n",
      "4239\n",
      "4242\n",
      "4244\n",
      "4245\n",
      "4255\n",
      "4257\n",
      "4261\n",
      "4262\n",
      "4264\n",
      "4267\n",
      "4271\n",
      "4272\n",
      "4275\n",
      "4277\n",
      "4283\n",
      "4289\n",
      "4292\n",
      "4297\n",
      "4298\n",
      "4307\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4317\n",
      "4318\n",
      "4321\n",
      "4325\n",
      "4328\n",
      "4333\n",
      "4340\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4350\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4357\n",
      "4359\n",
      "4363\n",
      "4364\n",
      "4366\n",
      "4377\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4390\n",
      "4392\n",
      "4393\n",
      "4396\n",
      "4404\n",
      "4406\n",
      "4408\n",
      "4414\n",
      "4428\n",
      "4429\n",
      "4435\n",
      "4443\n",
      "4447\n",
      "4450\n",
      "4452\n",
      "4457\n",
      "4458\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4477\n",
      "4478\n",
      "4485\n",
      "4486\n",
      "4488\n",
      "4494\n",
      "4495\n",
      "4510\n",
      "4512\n",
      "4523\n",
      "4528\n",
      "4529\n",
      "4531\n",
      "4532\n",
      "4542\n",
      "4546\n",
      "4547\n",
      "4551\n",
      "4554\n",
      "4559\n",
      "4561\n",
      "4569\n",
      "4580\n",
      "4581\n",
      "4584\n",
      "4586\n",
      "4588\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4607\n",
      "4611\n",
      "4613\n",
      "4619\n",
      "4620\n",
      "4622\n",
      "4626\n",
      "4628\n",
      "4633\n",
      "4637\n",
      "4638\n",
      "4656\n",
      "4659\n",
      "4662\n",
      "4664\n",
      "4666\n",
      "4667\n",
      "4674\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4689\n",
      "4692\n",
      "4694\n",
      "4708\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4721\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4731\n",
      "4733\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4747\n",
      "4749\n",
      "4751\n",
      "4753\n",
      "4757\n",
      "4762\n",
      "4767\n",
      "4771\n",
      "4774\n",
      "4779\n",
      "4781\n",
      "4788\n",
      "4789\n",
      "4791\n",
      "4797\n",
      "4804\n",
      "4807\n",
      "4808\n",
      "4819\n",
      "4821\n",
      "4826\n",
      "4828\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4857\n",
      "4861\n",
      "4863\n",
      "4865\n",
      "4873\n",
      "4877\n",
      "4889\n",
      "4890\n",
      "4892\n",
      "4895\n",
      "4901\n",
      "4906\n",
      "4925\n",
      "4930\n",
      "4934\n",
      "4937\n",
      "4941\n",
      "4943\n",
      "4951\n",
      "4954\n",
      "4956\n",
      "4962\n",
      "4964\n",
      "4966\n",
      "4969\n",
      "4978\n",
      "4983\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4993\n",
      "4996\n",
      "4998\n",
      "5001\n",
      "5004\n",
      "5005\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5011\n",
      "5017\n",
      "5019\n",
      "5022\n",
      "5025\n",
      "5027\n",
      "5029\n",
      "5030\n",
      "5034\n",
      "5038\n",
      "5043\n",
      "5050\n",
      "5052\n",
      "5053\n",
      "5066\n",
      "5069\n",
      "5071\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5084\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5092\n",
      "5094\n",
      "5096\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5116\n",
      "5120\n",
      "5129\n",
      "5130\n",
      "5132\n",
      "5134\n",
      "5136\n",
      "5143\n",
      "5145\n",
      "5150\n",
      "5155\n",
      "5161\n",
      "5165\n",
      "5167\n",
      "5169\n",
      "5170\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5177\n",
      "5178\n",
      "5191\n",
      "5197\n",
      "5204\n",
      "5209\n",
      "5212\n",
      "5213\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5225\n",
      "5230\n",
      "5233\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5241\n",
      "5242\n",
      "5245\n",
      "5247\n",
      "5252\n",
      "5254\n",
      "5258\n",
      "5271\n",
      "5273\n",
      "5274\n",
      "5276\n",
      "5279\n",
      "5287\n",
      "5293\n",
      "5294\n",
      "5297\n",
      "5298\n",
      "5300\n",
      "5305\n",
      "5310\n",
      "5311\n",
      "5315\n",
      "5320\n",
      "5321\n",
      "5323\n",
      "5328\n",
      "5339\n",
      "5341\n",
      "5343\n",
      "5345\n",
      "5348\n",
      "5350\n",
      "5356\n",
      "5358\n",
      "5360\n",
      "5362\n",
      "5364\n",
      "5367\n",
      "5369\n",
      "5377\n",
      "5378\n",
      "5380\n",
      "5381\n",
      "5385\n",
      "5395\n",
      "5403\n",
      "5408\n",
      "5413\n",
      "5419\n",
      "5423\n",
      "5425\n",
      "5426\n",
      "5435\n",
      "5443\n",
      "5444\n",
      "5446\n",
      "5459\n",
      "5461\n",
      "5465\n",
      "5474\n",
      "5478\n",
      "5487\n",
      "5496\n",
      "5500\n",
      "5504\n",
      "5506\n",
      "5508\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5515\n",
      "5517\n",
      "5522\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5531\n",
      "5538\n",
      "5544\n",
      "5551\n",
      "5554\n",
      "5555\n",
      "5559\n",
      "5567\n",
      "5569\n",
      "5571\n",
      "5573\n",
      "5575\n",
      "5577\n",
      "5578\n",
      "5601\n",
      "5604\n",
      "5620\n",
      "5644\n",
      "5646\n",
      "5650\n",
      "5651\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5664\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5687\n",
      "5689\n",
      "5699\n",
      "5707\n",
      "5710\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5729\n",
      "5733\n",
      "5736\n",
      "5737\n",
      "5742\n",
      "5747\n",
      "5755\n",
      "5756\n",
      "5760\n",
      "5761\n",
      "5765\n",
      "5768\n",
      "5770\n",
      "5772\n",
      "5776\n",
      "5778\n",
      "5780\n",
      "5812\n",
      "5815\n",
      "5816\n",
      "5819\n",
      "5822\n",
      "5832\n",
      "5836\n",
      "5838\n",
      "5844\n",
      "5847\n",
      "5849\n",
      "5858\n",
      "5859\n",
      "5861\n",
      "5862\n",
      "5864\n",
      "5867\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5875\n",
      "5893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ccf962960c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(skip)):\n",
    "    if skip[i]==1:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
