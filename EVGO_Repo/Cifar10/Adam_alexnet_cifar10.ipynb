{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ikarabayir\\AppData\\Local\\Continuum\\anaconda2\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 48)        1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 48)          192       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 96)          41568     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 96)          384       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 192)         166080    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 256)         442624    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,250,666\n",
      "Trainable params: 1,249,866\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "import os\n",
    "import keras\n",
    "import pickle\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "K.image_dim_ordering(), x_train.shape\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "def build_model(setseed):\n",
    "    \"\"\"\n",
    "    Builds test Keras model for Alexnet CIFAR-10\n",
    "    :param loss (str): Type of loss - must be one of Keras accepted keras losses\n",
    "    :return: Keras dense model of predefined structure\n",
    "    \"\"\"\n",
    "    input = Input(shape=[32, 32,3])\n",
    "    conv1 = Conv2D(48, (3,3), strides=(2,2), activation='relu', padding='same', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(input)\n",
    "    mp1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)\n",
    "    ban1 = BatchNormalization()(mp1)\n",
    "    \n",
    "    conv2 = Conv2D(96, (3,3), activation='relu', padding='same', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(ban1)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(conv2)\n",
    "    ban2 = BatchNormalization()(mp2)    \n",
    "    \n",
    "    conv3 = Conv2D(192, (3,3), activation='relu', padding='same', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(ban2)\n",
    "    conv4 = Conv2D(192, (3,3), activation='relu', padding='same', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(conv3)\n",
    "    conv5 = Conv2D(256, (3,3), activation='relu', padding='same', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(conv4)\n",
    "    \n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(conv5)\n",
    "    ban3 = BatchNormalization()(mp3) \n",
    "    flat= Flatten()(ban3)\n",
    "    dens1=Dense(512, activation='tanh', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(flat)\n",
    "    drop1=Dropout(0.5)(dens1)\n",
    "    dens2=Dense(256, activation='tanh', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(drop1)\n",
    "    drop2=Dropout(0.5)(dens2)   \n",
    "    probs=Dense(num_classes, activation='softmax', kernel_initializer=initializers.glorot_uniform(seed = setseed), bias_initializer=initializers.glorot_uniform(seed = setseed))(drop2)\n",
    "    \n",
    "    model = Model(input=input, output=probs)\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from keras.layers import Input\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "all_model = [None,None,None]\n",
    "losses = [None,None,None]\n",
    "\n",
    "prediction=[]\n",
    "\n",
    "all_score =[0,0,0]\n",
    "gr=[]\n",
    "wr=[]\n",
    "xwr=[]\n",
    "\n",
    "for i in range(3):\n",
    "    np.random.seed(25+i)\n",
    "    model = build_model(i+2)\n",
    "    all_model[i]=model\n",
    "    \n",
    "for i in range(3):    \n",
    "    weights = all_model[i].trainable_weights # weight tensors\n",
    "    weights = [weight for weight in weights] # filter down weights tensors to only ones which are trainable\n",
    "    gradients = all_model[i].optimizer.get_gradients(all_model[i].total_loss, weights) # gradient tensors\n",
    "    gr.append(gradients)\n",
    "    wr.append(weights)\n",
    "    xweights = all_model[i].non_trainable_weights # weight tensors\n",
    "    xweights = [weight for weight in xweights] # filter down weights tensors to only ones which are trainable\n",
    "    xwr.append(xweights)\n",
    "\n",
    "    losses[i]=all_model[i].total_loss\n",
    "    prediction.append(all_model[i].output)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "input_tensors = [all_model[0].inputs[0], # input data\n",
    "                 all_model[0].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[0].targets[0], # labels\n",
    "                 K.learning_phase(), # train or test mode\n",
    "                 all_model[1].inputs[0], # input data\n",
    "                 all_model[1].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[1].targets[0], # labels\n",
    "                 all_model[2].inputs[0], # input data\n",
    "                 all_model[2].sample_weights[0], # how much to weight each sample by\n",
    "                 all_model[2].targets[0], # labels\n",
    "                ]\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "minlos = K.argmin(losses)\n",
    "\n",
    "grr=[]\n",
    "for x in gr:\n",
    "    for y in x:\n",
    "        grr.append(y)\n",
    "\n",
    "upd_test= K.function(inputs=input_tensors, outputs=[ losses[0], losses[1], losses[2], minlos, prediction[0], prediction[1], prediction[2] ])\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "grad_best=[]\n",
    "grad_non0 = []\n",
    "grad_non1 = []\n",
    "\n",
    "\n",
    "weig_best=[]\n",
    "weig_non0 = []\n",
    "weig_non1 = []\n",
    "\n",
    "xweig_best=[]\n",
    "xweig_non0 = []\n",
    "xweig_non1 = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(gr[0])):\n",
    "    gr_ck=tf.concat([gr[0][i],gr[1][i], gr[2][i]],0)\n",
    "    newshape = (3, ) + (tuple(wr[0][i].shape))\n",
    "\n",
    "    \n",
    "    gr_ck2=tf.reshape(gr_ck, newshape)\n",
    "    \n",
    "    bb = gr_ck2[minlos]\n",
    "    grad_best.append(bb)\n",
    "    \n",
    "    nbb0 = gr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    nbb1 = gr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    nbc = tf.concat([nbb0,nbb1], 0)    \n",
    "    nbc = tf.reshape(nbc, (-1,))\n",
    "    newshape2 = (2, ) + (tuple(wr[0][i].shape))\n",
    "    \n",
    "    nbc2 = tf.reshape(nbc, newshape2) \n",
    "    nb0 = nbc2[0]\n",
    "    nb1 = nbc2[1]\n",
    "    grad_non0.append(nb0)\n",
    "    grad_non1.append(nb1)\n",
    "    \n",
    "\n",
    "    wr_ck=tf.concat([wr[0][i],wr[1][i], wr[2][i]],0)\n",
    "    \n",
    "    newshape = (3, ) + (tuple(wr[0][i].shape))\n",
    "    wr_ck2=tf.reshape(wr_ck, newshape) \n",
    "    bb2 = wr_ck2[minlos]\n",
    "    weig_best.append(bb2)\n",
    "    \n",
    "    #wb = wr_ck[minlos]\n",
    "    wnbb0 = wr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    wnbb1 = wr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "    wnbc = tf.concat([wnbb0,wnbb1],0)    \n",
    "    wnbc = tf.reshape(wnbc, (-1,))\n",
    "    newshape2 = (2, ) + (tuple(wr[0][i].shape))\n",
    "    \n",
    "    wnbc2 =tf.reshape(wnbc, newshape2)\n",
    "    wnb0 = wnbc2[0]\n",
    "    wnb1 = wnbc2[1]\n",
    "    weig_non0.append(wnb0)\n",
    "    weig_non1.append(wnb1)\n",
    "    \n",
    "    if i<len(xwr[0]):\n",
    "        print (i)\n",
    "        xwr_ck=tf.concat([xwr[0][i],xwr[1][i], xwr[2][i]], 0)\n",
    "\n",
    "        newshape = (3, ) + (tuple(xwr[0][i].shape))\n",
    "        \n",
    "        xwr_ck2=tf.reshape(xwr_ck, newshape)  \n",
    "        xbb2 = xwr_ck2[minlos]\n",
    "        xweig_best.append(xbb2)\n",
    "\n",
    "        #wb = wr_ck[minlos]\n",
    "        xwnbb0 = xwr_ck2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "        xwnbb1 = xwr_ck2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "        xwnbc = tf.concat([xwnbb0,xwnbb1], 0)    \n",
    "        \n",
    "        xwnbc = tf.reshape(xwnbc, (-1,))\n",
    "        newshape2 = (2, ) + (tuple(xwr[0][i].shape))\n",
    "         \n",
    "        xwnbc2 = tf.reshape(xwnbc, newshape2) \n",
    "        xwnb0 = xwnbc2[0]\n",
    "        xwnb1 = xwnbc2[1]\n",
    "        xweig_non0.append(xwnb0)\n",
    "        xweig_non1.append(xwnb1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "los=tf.stack([losses[0], losses[1], losses[2]])\n",
    "\n",
    "newshape = (3, )\n",
    "los2=tf.reshape(los, newshape) \n",
    "losbest = los2[minlos]\n",
    "\n",
    "#wb = wr_ck[minlos]\n",
    "los_0 = los2[0:minlos]                       #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "los_1 = los2[minlos+1:]                      #[0,enk) U (enk,] aralıklarının birleşimi bize nonbesti verecek\n",
    "loswnbc = tf.concat([los_0,los_1],0)    \n",
    "loswnbc = tf.reshape(loswnbc,(-1,))\n",
    "newshape2 = (2, )\n",
    "\n",
    "loswnbc2 = tf.reshape(loswnbc, newshape2)\n",
    "losss0 = loswnbc2[0]\n",
    "losss1 = loswnbc2[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adamb_m = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='m_best')) for t in weig_best]\n",
    "adamb_v = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='v_best')) for t in weig_best]\n",
    "adam0_m = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='m_0')) for t in weig_non0]\n",
    "adam0_v = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='v_0')) for t in weig_non0]\n",
    "adam1_m = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='m_1')) for t in weig_non1]\n",
    "adam1_v = [tf.Variable(tf.zeros(t.shape, dtype=tf.float32, name='v_2')) for t in weig_non1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "step_size = 0.001\n",
    "eps = 1e-8\n",
    "t = tf.Variable(1.0, name='iteration')\n",
    "\n",
    "upd2=[]\n",
    "\n",
    "for m, v, best, gbest,  param_i, in zip(adamb_m, adamb_v, weig_best, grad_best, wr[2]):\n",
    "    _m = beta_1 * m + (1 - beta_1) * gbest\n",
    "    _v = beta_2 * v + (1 - beta_2) * tf.pow(gbest, 2)\n",
    "    m_hat = _m / (1 - tf.pow(beta_1, t))\n",
    "    v_hat = _v / (1 - tf.pow(beta_2, t))\n",
    "    #m_hat = tf.cast(m_hat, tf.float32)\n",
    "    #v_hat = tf.cast(v_hat, tf.float32)\n",
    "    #upd2.extend([(m, _m)])\n",
    "    #upd2.extend([(v, _v)])\n",
    "    upd2.extend([tf.assign(m, _m)])\n",
    "    upd2.extend([tf.assign(v, _v)])\n",
    "    xbest = best - step_size * m_hat / (tf.sqrt(v_hat) + eps)\n",
    "    #upd2.extend([(param_i, xbest)])\n",
    "    upd2.extend([tf.assign(param_i, xbest)])\n",
    "\n",
    "\n",
    "upd2.extend([t.assign_add(1.0)])\n",
    "\n",
    "upd2.extend([tf.assign(param_i, v)\n",
    "        for param_i, v in zip(xwr[2], xweig_best)]\n",
    "    )    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_bb2= K.function(inputs=input_tensors, outputs=[ losses[0], losses[1], losses[2], minlos, prediction[0], prediction[1], prediction[2] ], updates=upd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train\n",
      "train loss score is :1.641719488117396\n",
      "train acc score is :0.42844868925831203\n",
      "test\n",
      "test loss score is :1.2766623463057265\n",
      "test acc score is :0.5346123417721519\n",
      "Epoch 1\n",
      "train\n",
      "train loss score is :1.2207874412960409\n",
      "train acc score is :0.5723905051150895\n",
      "test\n",
      "test loss score is :1.0571034959034076\n",
      "test acc score is :0.6252966772151899\n",
      "Epoch 2\n",
      "train\n",
      "train loss score is :1.0870582391234005\n",
      "train acc score is :0.6222826086956522\n",
      "test\n",
      "test loss score is :0.9883694147007375\n",
      "test acc score is :0.6438884493670886\n",
      "Epoch 3\n",
      "train\n",
      "train loss score is :0.9907171572451396\n",
      "train acc score is :0.6607057225063938\n",
      "test\n",
      "test loss score is :0.9352454394102097\n",
      "test acc score is :0.666435917721519\n",
      "Epoch 4\n",
      "train\n",
      "train loss score is :0.9271227505505847\n",
      "train acc score is :0.6831042199488491\n",
      "test\n",
      "test loss score is :0.873243958512439\n",
      "test acc score is :0.689873417721519\n",
      "Epoch 5\n",
      "train\n",
      "train loss score is :0.8816479871340115\n",
      "train acc score is :0.7005674552429667\n",
      "test\n",
      "test loss score is :0.8385285061748722\n",
      "test acc score is :0.7035205696202531\n",
      "Epoch 6\n",
      "train\n",
      "train loss score is :0.8415727243017967\n",
      "train acc score is :0.7148937020460358\n",
      "test\n",
      "test loss score is :0.8119883676872978\n",
      "test acc score is :0.7146954113924051\n",
      "Epoch 7\n",
      "train\n",
      "train loss score is :0.8059592935854517\n",
      "train acc score is :0.72818094629156\n",
      "test\n",
      "test loss score is :0.8049572643977178\n",
      "test acc score is :0.7169699367088608\n",
      "Epoch 8\n",
      "train\n",
      "train loss score is :0.7785042186679743\n",
      "train acc score is :0.7354739450127877\n",
      "test\n",
      "test loss score is :0.7795245270185833\n",
      "test acc score is :0.725870253164557\n",
      "Epoch 9\n",
      "train\n",
      "train loss score is :0.7504598098566465\n",
      "train acc score is :0.7472026854219949\n",
      "test\n",
      "test loss score is :0.7647297640767279\n",
      "test acc score is :0.7317049050632911\n",
      "Epoch 10\n",
      "train\n",
      "train loss score is :0.735496882720829\n",
      "train acc score is :0.7521779092071611\n",
      "test\n",
      "test loss score is :0.7321994197142275\n",
      "test acc score is :0.7474287974683544\n",
      "Epoch 11\n",
      "train\n",
      "train loss score is :0.7032908971428566\n",
      "train acc score is :0.7605099104859335\n",
      "test\n",
      "test loss score is :0.7086206377495693\n",
      "test acc score is :0.7524723101265823\n",
      "Epoch 12\n",
      "train\n",
      "train loss score is :0.6880906758939519\n",
      "train acc score is :0.7692615089514067\n",
      "test\n",
      "test loss score is :0.715099998478648\n",
      "test acc score is :0.7537579113924051\n",
      "Epoch 13\n",
      "train\n",
      "train loss score is :0.6676658841273974\n",
      "train acc score is :0.7768342391304348\n",
      "test\n",
      "test loss score is :0.7075017805718169\n",
      "test acc score is :0.7539556962025317\n",
      "Epoch 14\n",
      "train\n",
      "train loss score is :0.6401928688787744\n",
      "train acc score is :0.7838075447570333\n",
      "test\n",
      "test loss score is :0.7313109849449955\n",
      "test acc score is :0.7467365506329114\n",
      "Epoch 15\n",
      "train\n",
      "train loss score is :0.6388818841532368\n",
      "train acc score is :0.7850263746803069\n",
      "test\n",
      "test loss score is :0.7051068155825893\n",
      "test acc score is :0.756131329113924\n",
      "Epoch 16\n",
      "train\n",
      "train loss score is :0.6170150778444526\n",
      "train acc score is :0.792219469309463\n",
      "test\n",
      "test loss score is :0.692116311645206\n",
      "test acc score is :0.7611748417721519\n",
      "Epoch 17\n",
      "train\n",
      "train loss score is :0.6056280717482347\n",
      "train acc score is :0.7946571291560103\n",
      "test\n",
      "test loss score is :0.6818106755425658\n",
      "test acc score is :0.7667128164556962\n",
      "Epoch 18\n",
      "train\n",
      "train loss score is :0.5933442163231123\n",
      "train acc score is :0.7986333120204604\n",
      "test\n",
      "test loss score is :0.7009423072390919\n",
      "test acc score is :0.7631526898734177\n",
      "Epoch 19\n",
      "train\n",
      "train loss score is :0.5740721527763339\n",
      "train acc score is :0.8072450447570333\n",
      "test\n",
      "test loss score is :0.6814848095933094\n",
      "test acc score is :0.7676028481012658\n",
      "Epoch 20\n",
      "train\n",
      "train loss score is :0.5683817454539907\n",
      "train acc score is :0.8092231457800512\n",
      "test\n",
      "test loss score is :0.6652104606545424\n",
      "test acc score is :0.7730419303797469\n",
      "Epoch 21\n",
      "train\n",
      "train loss score is :0.5539049276381808\n",
      "train acc score is :0.8136588874680307\n",
      "test\n",
      "test loss score is :0.6726734614636325\n",
      "test acc score is :0.7731408227848101\n",
      "Epoch 22\n",
      "train\n",
      "train loss score is :0.5480554912934827\n",
      "train acc score is :0.8146978900255755\n",
      "test\n",
      "test loss score is :0.6494818803253053\n",
      "test acc score is :0.7745253164556962\n",
      "Epoch 23\n",
      "train\n",
      "train loss score is :0.5318290164403598\n",
      "train acc score is :0.8222506393861893\n",
      "test\n",
      "test loss score is :0.6672363333121131\n",
      "test acc score is :0.7768987341772152\n",
      "Epoch 24\n",
      "train\n",
      "train loss score is :0.5251559565020034\n",
      "train acc score is :0.8208320012787724\n",
      "test\n",
      "test loss score is :0.6590828142022784\n",
      "test acc score is :0.778184335443038\n",
      "Epoch 25\n",
      "train\n",
      "train loss score is :0.5172608327454008\n",
      "train acc score is :0.8265864769820972\n",
      "test\n",
      "test loss score is :0.6486156831813764\n",
      "test acc score is :0.7783821202531646\n",
      "Epoch 26\n",
      "train\n",
      "train loss score is :0.5078341996540194\n",
      "train acc score is :0.8299432544757033\n",
      "test\n",
      "test loss score is :0.6530917890464203\n",
      "test acc score is :0.7797666139240507\n",
      "Epoch 27\n",
      "train\n",
      "train loss score is :0.49770000213971527\n",
      "train acc score is :0.8337396099744245\n",
      "test\n",
      "test loss score is :0.6782885663494279\n",
      "test acc score is :0.7743275316455697\n",
      "Epoch 28\n",
      "train\n",
      "train loss score is :0.48937131249157667\n",
      "train acc score is :0.8361772698209718\n",
      "test\n",
      "test loss score is :0.6566752602782431\n",
      "test acc score is :0.7806566455696202\n",
      "Epoch 29\n",
      "train\n",
      "train loss score is :0.48095689885451665\n",
      "train acc score is :0.8385549872122762\n",
      "test\n",
      "test loss score is :0.65690671284742\n",
      "test acc score is :0.7808544303797469\n",
      "Epoch 30\n",
      "train\n",
      "train loss score is :0.46822806092365016\n",
      "train acc score is :0.8415720907928389\n",
      "test\n",
      "test loss score is :0.6631265879620479\n",
      "test acc score is :0.7818433544303798\n",
      "Epoch 31\n",
      "train\n",
      "train loss score is :0.4655147509273056\n",
      "train acc score is :0.8434303069053708\n",
      "test\n",
      "test loss score is :0.6679428792263888\n",
      "test acc score is :0.7777887658227848\n",
      "Epoch 32\n",
      "train\n",
      "train loss score is :0.4581878584573793\n",
      "train acc score is :0.844309462915601\n",
      "test\n",
      "test loss score is :0.6737789783296706\n",
      "test acc score is :0.7761075949367089\n",
      "Epoch 33\n",
      "train\n",
      "train loss score is :0.4563413394991394\n",
      "train acc score is :0.8453085038363172\n",
      "test\n",
      "test loss score is :0.6602060240280779\n",
      "test acc score is :0.7780854430379747\n",
      "Epoch 34\n",
      "train\n",
      "train loss score is :0.44629513420869626\n",
      "train acc score is :0.850263746803069\n",
      "test\n",
      "test loss score is :0.6795235332808917\n",
      "test acc score is :0.7787776898734177\n",
      "Epoch 35\n",
      "train\n",
      "train loss score is :0.4386080483169964\n",
      "train acc score is :0.8519621163682864\n",
      "test\n",
      "test loss score is :0.6662027281296404\n",
      "test acc score is :0.7804588607594937\n",
      "Epoch 36\n",
      "train\n",
      "train loss score is :0.4295955555289603\n",
      "train acc score is :0.8538802749360613\n",
      "test\n",
      "test loss score is :0.6689705282826967\n",
      "test acc score is :0.7822389240506329\n",
      "Epoch 37\n",
      "train\n",
      "train loss score is :0.4291493937068278\n",
      "train acc score is :0.8550191815856778\n",
      "test\n",
      "test loss score is :0.654323241213643\n",
      "test acc score is :0.7857990506329114\n",
      "Epoch 38\n",
      "train\n",
      "train loss score is :0.42031252566162886\n",
      "train acc score is :0.8572570332480819\n",
      "test\n",
      "test loss score is :0.6729629630152183\n",
      "test acc score is :0.7852056962025317\n",
      "Epoch 39\n",
      "train\n",
      "train loss score is :0.410697263553548\n",
      "train acc score is :0.8623321611253197\n",
      "test\n",
      "test loss score is :0.6667796199363244\n",
      "test acc score is :0.7813488924050633\n",
      "Epoch 40\n",
      "train\n",
      "train loss score is :0.40847515494889003\n",
      "train acc score is :0.863031489769821\n",
      "test\n",
      "test loss score is :0.6683753928806209\n",
      "test acc score is :0.7837223101265823\n",
      "Epoch 41\n",
      "train\n",
      "train loss score is :0.40545050681704453\n",
      "train acc score is :0.863590952685422\n",
      "test\n",
      "test loss score is :0.6568412196032608\n",
      "test acc score is :0.7876780063291139\n",
      "Epoch 42\n",
      "train\n",
      "train loss score is :0.3977651999467779\n",
      "train acc score is :0.8651694373401535\n",
      "test\n",
      "test loss score is :0.673943053035042\n",
      "test acc score is :0.7827333860759493\n",
      "Epoch 43\n",
      "train\n",
      "train loss score is :0.3944968752505834\n",
      "train acc score is :0.8657488810741688\n",
      "test\n",
      "test loss score is :0.6575209800201126\n",
      "test acc score is :0.786689082278481\n",
      "Epoch 44\n",
      "train\n",
      "train loss score is :0.38484500879255096\n",
      "train acc score is :0.8706441815856778\n",
      "test\n",
      "test loss score is :0.6729878636100625\n",
      "test acc score is :0.7861946202531646\n",
      "Epoch 45\n",
      "train\n",
      "train loss score is :0.3805092279525364\n",
      "train acc score is :0.871463395140665\n",
      "test\n",
      "test loss score is :0.6654063350037683\n",
      "test acc score is :0.7865901898734177\n",
      "Epoch 46\n",
      "train\n",
      "train loss score is :0.3812742710990064\n",
      "train acc score is :0.8717830882352942\n",
      "test\n",
      "test loss score is :0.6741555119051209\n",
      "test acc score is :0.7847112341772152\n",
      "Epoch 47\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss score is :0.37399929229293943\n",
      "train acc score is :0.8734414961636828\n",
      "test\n",
      "test loss score is :0.6660121041291123\n",
      "test acc score is :0.787381329113924\n",
      "Epoch 48\n",
      "train\n",
      "train loss score is :0.36716907349465144\n",
      "train acc score is :0.8759590792838875\n",
      "test\n",
      "test loss score is :0.6661314421062228\n",
      "test acc score is :0.7908425632911392\n",
      "Epoch 49\n",
      "train\n",
      "train loss score is :0.3594636295343299\n",
      "train acc score is :0.8794157608695652\n",
      "test\n",
      "test loss score is :0.6790520107444329\n",
      "test acc score is :0.7877768987341772\n",
      "Epoch 50\n",
      "train\n",
      "train loss score is :0.35940375979370476\n",
      "train acc score is :0.8802149936061381\n",
      "test\n",
      "test loss score is :0.6918040232945092\n",
      "test acc score is :0.7884691455696202\n",
      "Epoch 51\n",
      "train\n",
      "train loss score is :0.3592611526703591\n",
      "train acc score is :0.8783567774936062\n",
      "test\n",
      "test loss score is :0.6757061394709575\n",
      "test acc score is :0.791435917721519\n",
      "Epoch 52\n",
      "train\n",
      "train loss score is :0.34568424776310813\n",
      "train acc score is :0.8828924232736572\n",
      "test\n",
      "test loss score is :0.6796669159320337\n",
      "test acc score is :0.7880735759493671\n",
      "Epoch 53\n",
      "train\n",
      "train loss score is :0.3485871652793854\n",
      "train acc score is :0.8813139386189258\n",
      "test\n",
      "test loss score is :0.6944731258893315\n",
      "test acc score is :0.7857001582278481\n",
      "Epoch 54\n",
      "train\n",
      "train loss score is :0.3453588315173793\n",
      "train acc score is :0.8838914641943734\n",
      "test\n",
      "test loss score is :0.6898662756326832\n",
      "test acc score is :0.7887658227848101\n",
      "Epoch 55\n",
      "train\n",
      "train loss score is :0.34314845873952826\n",
      "train acc score is :0.8836716751918159\n",
      "test\n",
      "test loss score is :0.6758865523564664\n",
      "test acc score is :0.7944026898734177\n",
      "Epoch 56\n",
      "train\n",
      "train loss score is :0.3393576076573423\n",
      "train acc score is :0.8849904092071611\n",
      "test\n",
      "test loss score is :0.6829265734251542\n",
      "test acc score is :0.7928204113924051\n",
      "Epoch 57\n",
      "train\n",
      "train loss score is :0.3295720146249627\n",
      "train acc score is :0.8879076086956522\n",
      "test\n",
      "test loss score is :0.684836878570952\n",
      "test acc score is :0.7909414556962026\n",
      "Epoch 58\n",
      "train\n",
      "train loss score is :0.3310067721683046\n",
      "train acc score is :0.8896059782608695\n",
      "test\n",
      "test loss score is :0.7158046567553207\n",
      "test acc score is :0.784315664556962\n",
      "Epoch 59\n",
      "train\n",
      "train loss score is :0.3247027968430458\n",
      "train acc score is :0.8907848465473146\n",
      "test\n",
      "test loss score is :0.6800186943404282\n",
      "test acc score is :0.7917325949367089\n",
      "Epoch 60\n",
      "train\n",
      "train loss score is :0.31406880074830923\n",
      "train acc score is :0.8940816815856778\n",
      "test\n",
      "test loss score is :0.7031073270342018\n",
      "test acc score is :0.7858979430379747\n",
      "Epoch 61\n",
      "train\n",
      "train loss score is :0.31852808303159214\n",
      "train acc score is :0.8934822570332481\n",
      "test\n",
      "test loss score is :0.6986302314679834\n",
      "test acc score is :0.7877768987341772\n",
      "Epoch 62\n",
      "train\n",
      "train loss score is :0.3155598806126801\n",
      "train acc score is :0.893662084398977\n",
      "test\n",
      "test loss score is :0.708544721709022\n",
      "test acc score is :0.7884691455696202\n",
      "Epoch 63\n",
      "train\n",
      "train loss score is :0.31193229483673945\n",
      "train acc score is :0.8950607416879796\n",
      "test\n",
      "test loss score is :0.6988055366504041\n",
      "test acc score is :0.7874802215189873\n",
      "Epoch 64\n",
      "train\n",
      "train loss score is :0.31183839013890535\n",
      "train acc score is :0.8938219309462916\n",
      "test\n",
      "test loss score is :0.7152682170271873\n",
      "test acc score is :0.7877768987341772\n",
      "Epoch 65\n",
      "train\n",
      "train loss score is :0.30377252174117375\n",
      "train acc score is :0.8977181905370843\n",
      "test\n",
      "test loss score is :0.6955412247135669\n",
      "test acc score is :0.7876780063291139\n",
      "Epoch 66\n",
      "train\n",
      "train loss score is :0.3045716044133353\n",
      "train acc score is :0.8970588235294118\n",
      "test\n",
      "test loss score is :0.7157552313955524\n",
      "test acc score is :0.7827333860759493\n",
      "Epoch 67\n",
      "train\n",
      "train loss score is :0.2945753939621284\n",
      "train acc score is :0.9009351023017903\n",
      "test\n",
      "test loss score is :0.7091256788448442\n",
      "test acc score is :0.7880735759493671\n",
      "Epoch 68\n",
      "train\n",
      "train loss score is :0.29265679497166974\n",
      "train acc score is :0.9012947570332481\n",
      "test\n",
      "test loss score is :0.7205813318208049\n",
      "test acc score is :0.7863924050632911\n",
      "Epoch 69\n",
      "train\n",
      "train loss score is :0.2984138603805733\n",
      "train acc score is :0.899616368286445\n",
      "test\n",
      "test loss score is :0.6985359842641444\n",
      "test acc score is :0.7898536392405063\n",
      "Epoch 70\n",
      "train\n",
      "train loss score is :0.29134017608278545\n",
      "train acc score is :0.9033927429667519\n",
      "test\n",
      "test loss score is :0.7164165592646297\n",
      "test acc score is :0.7851068037974683\n",
      "Epoch 71\n",
      "train\n",
      "train loss score is :0.2890420537203779\n",
      "train acc score is :0.9024536445012787\n",
      "test\n",
      "test loss score is :0.7182647591527505\n",
      "test acc score is :0.7941060126582279\n",
      "Epoch 72\n",
      "train\n",
      "train loss score is :0.28319376043956296\n",
      "train acc score is :0.9051110933503836\n",
      "test\n",
      "test loss score is :0.7220296837106536\n",
      "test acc score is :0.7851068037974683\n",
      "Epoch 73\n",
      "train\n",
      "train loss score is :0.2798684125532732\n",
      "train acc score is :0.9055706521739131\n",
      "test\n",
      "test loss score is :0.7253695120917091\n",
      "test acc score is :0.7851068037974683\n",
      "Epoch 74\n",
      "train\n",
      "train loss score is :0.28525443747639656\n",
      "train acc score is :0.9041520140664961\n",
      "test\n",
      "test loss score is :0.710849106877665\n",
      "test acc score is :0.7828322784810127\n",
      "Epoch 75\n",
      "train\n",
      "train loss score is :0.2738091420772893\n",
      "train acc score is :0.9068893861892583\n",
      "test\n",
      "test loss score is :0.7317096968240375\n",
      "test acc score is :0.7844145569620253\n",
      "Epoch 76\n",
      "train\n",
      "train loss score is :0.2752924677403763\n",
      "train acc score is :0.9064697890025576\n",
      "test\n",
      "test loss score is :0.7268054546151734\n",
      "test acc score is :0.788370253164557\n",
      "Epoch 77\n",
      "train\n",
      "train loss score is :0.2777312871002023\n",
      "train acc score is :0.9070692135549873\n",
      "test\n",
      "test loss score is :0.7106434343547761\n",
      "test acc score is :0.7912381329113924\n",
      "Epoch 78\n",
      "train\n",
      "train loss score is :0.2642132794327291\n",
      "train acc score is :0.9123041879795396\n",
      "test\n",
      "test loss score is :0.7308471785693229\n",
      "test acc score is :0.7904469936708861\n",
      "Epoch 79\n",
      "train\n",
      "train loss score is :0.26697749771234935\n",
      "train acc score is :0.9106657608695652\n",
      "test\n",
      "test loss score is :0.7323652026774008\n",
      "test acc score is :0.7919303797468354\n",
      "Epoch 80\n",
      "train\n",
      "train loss score is :0.2657050411586109\n",
      "train acc score is :0.9104259910485933\n",
      "test\n",
      "test loss score is :0.7417807930349549\n",
      "test acc score is :0.7889636075949367\n",
      "Epoch 81\n",
      "train\n",
      "train loss score is :0.2669241102817266\n",
      "train acc score is :0.9113650895140665\n",
      "test\n",
      "test loss score is :0.7229164374780052\n",
      "test acc score is :0.7863924050632911\n",
      "Epoch 82\n",
      "train\n",
      "train loss score is :0.26281417015454045\n",
      "train acc score is :0.9114849744245525\n",
      "test\n",
      "test loss score is :0.7202206403017044\n",
      "test acc score is :0.7910403481012658\n",
      "Epoch 83\n",
      "train\n",
      "train loss score is :0.25861703387230556\n",
      "train acc score is :0.9121443414322251\n",
      "test\n",
      "test loss score is :0.7411872289037402\n",
      "test acc score is :0.790743670886076\n",
      "Epoch 84\n",
      "train\n",
      "train loss score is :0.2608697992628035\n",
      "train acc score is :0.910905530690537\n",
      "test\n",
      "test loss score is :0.7175181428842907\n",
      "test acc score is :0.7916337025316456\n",
      "Epoch 85\n",
      "train\n",
      "train loss score is :0.2577705072129474\n",
      "train acc score is :0.9143022698209718\n",
      "test\n",
      "test loss score is :0.7250878697709192\n",
      "test acc score is :0.7895569620253164\n",
      "Epoch 86\n",
      "train\n",
      "train loss score is :0.2559174625369746\n",
      "train acc score is :0.9144621163682864\n",
      "test\n",
      "test loss score is :0.7644717202910895\n",
      "test acc score is :0.7891613924050633\n",
      "Epoch 87\n",
      "train\n",
      "train loss score is :0.24829728433581263\n",
      "train acc score is :0.9171195652173914\n",
      "test\n",
      "test loss score is :0.7364264402208449\n",
      "test acc score is :0.7930181962025317\n",
      "Epoch 88\n",
      "train\n",
      "train loss score is :0.25403760411702764\n",
      "train acc score is :0.9149616368286445\n",
      "test\n",
      "test loss score is :0.7259468910626218\n",
      "test acc score is :0.7916337025316456\n",
      "Epoch 89\n",
      "train\n",
      "train loss score is :0.24382166997970217\n",
      "train acc score is :0.9169996803069054\n",
      "test\n",
      "test loss score is :0.7606563028655474\n",
      "test acc score is :0.7856012658227848\n",
      "Epoch 90\n",
      "train\n",
      "train loss score is :0.2479287834023423\n",
      "train acc score is :0.9151214833759591\n",
      "test\n",
      "test loss score is :0.7367977100082591\n",
      "test acc score is :0.791435917721519\n",
      "Epoch 91\n",
      "train\n",
      "train loss score is :0.2465834913446623\n",
      "train acc score is :0.9169197570332481\n",
      "test\n",
      "test loss score is :0.7279787308807615\n",
      "test acc score is :0.7913370253164557\n",
      "Epoch 92\n",
      "train\n",
      "train loss score is :0.2367650110731878\n",
      "train acc score is :0.9196371483375959\n",
      "test\n",
      "test loss score is :0.7307857846534704\n",
      "test acc score is :0.7946004746835443\n",
      "Epoch 93\n",
      "train\n",
      "train loss score is :0.23983611296052518\n",
      "train acc score is :0.9191576086956522\n",
      "test\n",
      "test loss score is :0.7261197661297231\n",
      "test acc score is :0.7903481012658228\n",
      "Epoch 94\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss score is :0.23645506360951593\n",
      "train acc score is :0.9205562659846548\n",
      "test\n",
      "test loss score is :0.7456963370683827\n",
      "test acc score is :0.7906447784810127\n",
      "Epoch 95\n",
      "train\n",
      "train loss score is :0.22780835189287316\n",
      "train acc score is :0.9229339833759591\n",
      "test\n",
      "test loss score is :0.7656797910038429\n",
      "test acc score is :0.7850079113924051\n",
      "Epoch 96\n",
      "train\n",
      "train loss score is :0.23402653500209075\n",
      "train acc score is :0.921875\n",
      "test\n",
      "test loss score is :0.7397399369297148\n",
      "test acc score is :0.7884691455696202\n",
      "Epoch 97\n",
      "train\n",
      "train loss score is :0.23341474477249338\n",
      "train acc score is :0.9209159207161125\n",
      "test\n",
      "test loss score is :0.7637062619758558\n",
      "test acc score is :0.7882713607594937\n",
      "Epoch 98\n",
      "train\n",
      "train loss score is :0.2322481539138519\n",
      "train acc score is :0.9217950767263428\n",
      "test\n",
      "test loss score is :0.7589647887816912\n",
      "test acc score is :0.784315664556962\n",
      "Epoch 99\n",
      "train\n",
      "train loss score is :0.22716388096818535\n",
      "train acc score is :0.9235134271099744\n",
      "test\n",
      "test loss score is :0.7474272448711002\n",
      "test acc score is :0.7906447784810127\n",
      "Epoch 100\n",
      "train\n",
      "train loss score is :0.22750166223844145\n",
      "train acc score is :0.9232137148337596\n",
      "test\n",
      "test loss score is :0.7726969472545234\n",
      "test acc score is :0.784315664556962\n",
      "Epoch 101\n",
      "train\n",
      "train loss score is :0.23169419766806276\n",
      "train acc score is :0.9211956521739131\n",
      "test\n",
      "test loss score is :0.7575111997938608\n",
      "test acc score is :0.7900514240506329\n",
      "Epoch 102\n",
      "train\n",
      "train loss score is :0.22280007068191648\n",
      "train acc score is :0.9237931585677749\n",
      "test\n",
      "test loss score is :0.7819103532105307\n",
      "test acc score is :0.7849090189873418\n",
      "Epoch 103\n",
      "train\n",
      "train loss score is :0.2246598153496566\n",
      "train acc score is :0.9240728900255755\n",
      "test\n",
      "test loss score is :0.77578111200393\n",
      "test acc score is :0.786689082278481\n",
      "Epoch 104\n",
      "train\n",
      "train loss score is :0.22610342160553273\n",
      "train acc score is :0.9247122762148338\n",
      "test\n",
      "test loss score is :0.7757955126558678\n",
      "test acc score is :0.7893591772151899\n",
      "Epoch 105\n",
      "train\n",
      "train loss score is :0.22402193603556023\n",
      "train acc score is :0.9238531010230179\n",
      "test\n",
      "test loss score is :0.7573125001184547\n",
      "test acc score is :0.7915348101265823\n",
      "Epoch 106\n",
      "train\n",
      "train loss score is :0.22157931127263913\n",
      "train acc score is :0.9251118925831202\n",
      "test\n",
      "test loss score is :0.7667057769773882\n",
      "test acc score is :0.7839200949367089\n",
      "Epoch 107\n",
      "train\n",
      "train loss score is :0.21450172522869868\n",
      "train acc score is :0.9280490728900256\n",
      "test\n",
      "test loss score is :0.777076015555406\n",
      "test acc score is :0.7928204113924051\n",
      "Epoch 108\n",
      "train\n",
      "train loss score is :0.21831882819342796\n",
      "train acc score is :0.9258112212276215\n",
      "test\n",
      "test loss score is :0.7919759122253973\n",
      "test acc score is :0.7844145569620253\n",
      "Epoch 109\n",
      "train\n",
      "train loss score is :0.213719819712898\n",
      "train acc score is :0.9284287084398977\n",
      "test\n",
      "test loss score is :0.7898397635244117\n",
      "test acc score is :0.7865901898734177\n",
      "Epoch 110\n",
      "train\n",
      "train loss score is :0.21230610578185152\n",
      "train acc score is :0.9287084398976982\n",
      "test\n",
      "test loss score is :0.7800651117216183\n",
      "test acc score is :0.7899525316455697\n",
      "Epoch 111\n",
      "train\n",
      "train loss score is :0.21348058499986558\n",
      "train acc score is :0.9285885549872123\n",
      "test\n",
      "test loss score is :0.7780203102510187\n",
      "test acc score is :0.7905458860759493\n",
      "Epoch 112\n",
      "train\n",
      "train loss score is :0.20452996362429446\n",
      "train acc score is :0.9316256393861893\n",
      "test\n",
      "test loss score is :0.7861694840690757\n",
      "test acc score is :0.7888647151898734\n",
      "Epoch 113\n",
      "train\n",
      "train loss score is :0.20775710332119252\n",
      "train acc score is :0.9301670396419437\n",
      "test\n",
      "test loss score is :0.7764823817754094\n",
      "test acc score is :0.7952927215189873\n",
      "Epoch 114\n",
      "train\n",
      "train loss score is :0.20763500078159677\n",
      "train acc score is :0.9311660805626598\n",
      "test\n",
      "test loss score is :0.7957785889694963\n",
      "test acc score is :0.7837223101265823\n",
      "Epoch 115\n",
      "train\n",
      "train loss score is :0.2058580216934995\n",
      "train acc score is :0.9293877877237852\n",
      "test\n",
      "test loss score is :0.7813862643287152\n",
      "test acc score is :0.7894580696202531\n",
      "Epoch 116\n",
      "train\n",
      "train loss score is :0.20650413882968677\n",
      "train acc score is :0.9309063299232737\n",
      "test\n",
      "test loss score is :0.7641867172868946\n",
      "test acc score is :0.7878757911392406\n",
      "Epoch 117\n",
      "train\n",
      "train loss score is :0.21365307393910177\n",
      "train acc score is :0.9286285166240409\n",
      "test\n",
      "test loss score is :0.7475279030166094\n",
      "test acc score is :0.7939082278481012\n",
      "Epoch 118\n",
      "train\n",
      "train loss score is :0.19622010601889295\n",
      "train acc score is :0.933843510230179\n",
      "test\n",
      "test loss score is :0.771726907525636\n",
      "test acc score is :0.7925237341772152\n",
      "Epoch 119\n",
      "train\n",
      "train loss score is :0.20180661362760208\n",
      "train acc score is :0.9315656969309463\n",
      "test\n",
      "test loss score is :0.7874066897585422\n",
      "test acc score is :0.7867879746835443\n",
      "Epoch 120\n",
      "train\n",
      "train loss score is :0.19857309444728868\n",
      "train acc score is :0.9331641624040921\n",
      "test\n",
      "test loss score is :0.7835298703063892\n",
      "test acc score is :0.7858979430379747\n",
      "Epoch 121\n",
      "train\n",
      "train loss score is :0.2058658217892165\n",
      "train acc score is :0.9311860613810742\n",
      "test\n",
      "test loss score is :0.7789860920438284\n",
      "test acc score is :0.7875791139240507\n",
      "Epoch 122\n",
      "train\n",
      "train loss score is :0.19857679256011762\n",
      "train acc score is :0.9326246803069054\n",
      "test\n",
      "test loss score is :0.781582850444166\n",
      "test acc score is :0.7862935126582279\n",
      "Epoch 123\n",
      "train\n",
      "train loss score is :0.18913482642158522\n",
      "train acc score is :0.9368606138107417\n",
      "test\n",
      "test loss score is :0.7770941686592524\n",
      "test acc score is :0.7892602848101266\n",
      "Epoch 124\n",
      "train\n",
      "train loss score is :0.20366881130372777\n",
      "train acc score is :0.931046195652174\n",
      "test\n",
      "test loss score is :0.7660547422268723\n",
      "test acc score is :0.790743670886076\n",
      "Epoch 125\n",
      "train\n",
      "train loss score is :0.193963119374288\n",
      "train acc score is :0.9354020140664961\n",
      "test\n",
      "test loss score is :0.7907858338159851\n",
      "test acc score is :0.7875791139240507\n",
      "Epoch 126\n",
      "train\n",
      "train loss score is :0.1963072499484205\n",
      "train acc score is :0.9340033567774936\n",
      "test\n",
      "test loss score is :0.781550143338457\n",
      "test acc score is :0.7913370253164557\n",
      "Epoch 127\n",
      "train\n",
      "train loss score is :0.19549087403089646\n",
      "train acc score is :0.9347026854219949\n",
      "test\n",
      "test loss score is :0.7996909199636194\n",
      "test acc score is :0.7890625\n",
      "Epoch 128\n",
      "train\n",
      "train loss score is :0.19392477497077354\n",
      "train acc score is :0.9355418797953964\n",
      "test\n",
      "test loss score is :0.7890826384713755\n",
      "test acc score is :0.7889636075949367\n",
      "Epoch 129\n",
      "train\n",
      "train loss score is :0.19066527602084152\n",
      "train acc score is :0.9357217071611253\n",
      "test\n",
      "test loss score is :0.7984861736244793\n",
      "test acc score is :0.7874802215189873\n",
      "Epoch 130\n",
      "train\n",
      "train loss score is :0.18679164579647886\n",
      "train acc score is :0.9361213235294118\n",
      "test\n",
      "test loss score is :0.7768058627843857\n",
      "test acc score is :0.7928204113924051\n",
      "Epoch 131\n",
      "train\n",
      "train loss score is :0.189046649452861\n",
      "train acc score is :0.9392183503836317\n",
      "test\n",
      "test loss score is :0.7910490493419804\n",
      "test acc score is :0.7924248417721519\n",
      "Epoch 132\n",
      "train\n",
      "train loss score is :0.1879776011475974\n",
      "train acc score is :0.9361812659846548\n",
      "test\n",
      "test loss score is :0.8262491758111157\n",
      "test acc score is :0.7835245253164557\n",
      "Epoch 133\n",
      "train\n",
      "train loss score is :0.19431644335122364\n",
      "train acc score is :0.9355019181585678\n",
      "test\n",
      "test loss score is :0.8034765493077568\n",
      "test acc score is :0.7850079113924051\n",
      "Epoch 134\n",
      "train\n",
      "train loss score is :0.1830834288416845\n",
      "train acc score is :0.9379995204603581\n",
      "test\n",
      "test loss score is :0.7962926594139654\n",
      "test acc score is :0.7878757911392406\n",
      "Epoch 135\n",
      "train\n",
      "train loss score is :0.18672388335666085\n",
      "train acc score is :0.9383591751918159\n",
      "test\n",
      "test loss score is :0.7974663967195945\n",
      "test acc score is :0.7904469936708861\n",
      "Epoch 136\n",
      "train\n",
      "train loss score is :0.1808813280375946\n",
      "train acc score is :0.9383791560102301\n",
      "test\n",
      "test loss score is :0.8121949558771109\n",
      "test acc score is :0.7913370253164557\n",
      "Epoch 137\n",
      "train\n",
      "train loss score is :0.18338990007596248\n",
      "train acc score is :0.939298273657289\n",
      "test\n",
      "test loss score is :0.8163358229625074\n",
      "test acc score is :0.7832278481012658\n",
      "Epoch 138\n",
      "train\n",
      "train loss score is :0.18535025276796288\n",
      "train acc score is :0.9376598465473146\n",
      "test\n",
      "test loss score is :0.8000170609241799\n",
      "test acc score is :0.7879746835443038\n",
      "Epoch 139\n",
      "train\n",
      "train loss score is :0.18239305330359418\n",
      "train acc score is :0.93911844629156\n",
      "test\n",
      "test loss score is :0.8041880160947389\n",
      "test acc score is :0.7884691455696202\n",
      "Epoch 140\n",
      "train\n",
      "train loss score is :0.18182685656849382\n",
      "train acc score is :0.9380794437340153\n",
      "test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss score is :0.7942795245141923\n",
      "test acc score is :0.7861946202531646\n",
      "Epoch 141\n",
      "train\n",
      "train loss score is :0.17997751759408076\n",
      "train acc score is :0.9381993286445013\n",
      "test\n",
      "test loss score is :0.8019487408897544\n",
      "test acc score is :0.7901503164556962\n",
      "Epoch 142\n",
      "train\n",
      "train loss score is :0.181668031884505\n",
      "train acc score is :0.9404571611253197\n",
      "test\n",
      "test loss score is :0.7906853384986708\n",
      "test acc score is :0.7913370253164557\n",
      "Epoch 143\n",
      "train\n",
      "train loss score is :0.17526601222069824\n",
      "train acc score is :0.9401374680306905\n",
      "test\n",
      "test loss score is :0.7991308943380283\n",
      "test acc score is :0.7931170886075949\n",
      "Epoch 144\n",
      "train\n",
      "train loss score is :0.17578990237258585\n",
      "train acc score is :0.9412963554987213\n",
      "test\n",
      "test loss score is :0.8220266129208517\n",
      "test acc score is :0.7871835443037974\n",
      "Epoch 145\n",
      "train\n",
      "train loss score is :0.18221335461758592\n",
      "train acc score is :0.9400175831202046\n",
      "test\n",
      "test loss score is :0.7833029978165899\n",
      "test acc score is :0.791435917721519\n",
      "Epoch 146\n",
      "train\n",
      "train loss score is :0.1788490849506596\n",
      "train acc score is :0.9404971227621484\n",
      "test\n",
      "test loss score is :0.7826614754298066\n",
      "test acc score is :0.7928204113924051\n",
      "Epoch 147\n",
      "train\n",
      "train loss score is :0.17844201896406348\n",
      "train acc score is :0.9406969309462916\n",
      "test\n",
      "test loss score is :0.8348440784442274\n",
      "test acc score is :0.7827333860759493\n",
      "Epoch 148\n",
      "train\n",
      "train loss score is :0.179191410055627\n",
      "train acc score is :0.94059702685422\n",
      "test\n",
      "test loss score is :0.8232591587908661\n",
      "test acc score is :0.7875791139240507\n",
      "Epoch 149\n",
      "train\n",
      "train loss score is :0.1716182321557761\n",
      "train acc score is :0.9412364130434783\n",
      "test\n",
      "test loss score is :0.8071713125026678\n",
      "test acc score is :0.7911392405063291\n",
      "Epoch 150\n",
      "train\n",
      "train loss score is :0.17377258578072424\n",
      "train acc score is :0.9419557225063938\n",
      "test\n",
      "test loss score is :0.8213424525117572\n",
      "test acc score is :0.7900514240506329\n",
      "Epoch 151\n",
      "train\n",
      "train loss score is :0.17410825187211756\n",
      "train acc score is :0.9415760869565217\n",
      "test\n",
      "test loss score is :0.8062562663343888\n",
      "test acc score is :0.787381329113924\n",
      "Epoch 152\n",
      "train\n",
      "train loss score is :0.1754921544938708\n",
      "train acc score is :0.9401574488491049\n",
      "test\n",
      "test loss score is :0.8039702286920215\n",
      "test acc score is :0.7918314873417721\n",
      "Epoch 153\n",
      "train\n",
      "train loss score is :0.16855501747020826\n",
      "train acc score is :0.9426550511508951\n",
      "test\n",
      "test loss score is :0.8139119589630561\n",
      "test acc score is :0.7925237341772152\n",
      "Epoch 154\n",
      "train\n",
      "train loss score is :0.17584845074035627\n",
      "train acc score is :0.9399576406649617\n",
      "test\n",
      "test loss score is :0.8161188696004167\n",
      "test acc score is :0.7917325949367089\n",
      "Epoch 155\n",
      "train\n",
      "train loss score is :0.16816267616513286\n",
      "train acc score is :0.9433343989769821\n",
      "test\n",
      "test loss score is :0.8012760528186454\n",
      "test acc score is :0.7925237341772152\n",
      "Epoch 156\n",
      "train\n",
      "train loss score is :0.16991719645459938\n",
      "train acc score is :0.943454283887468\n",
      "test\n",
      "test loss score is :0.8130686590565911\n",
      "test acc score is :0.7899525316455697\n",
      "Epoch 157\n",
      "train\n",
      "train loss score is :0.16554292590092973\n",
      "train acc score is :0.943574168797954\n",
      "test\n",
      "test loss score is :0.8189215388479112\n",
      "test acc score is :0.7875791139240507\n",
      "Epoch 158\n",
      "train\n",
      "train loss score is :0.16172379499201275\n",
      "train acc score is :0.9468310421994884\n",
      "test\n",
      "test loss score is :0.8052408348155927\n",
      "test acc score is :0.7916337025316456\n",
      "Epoch 159\n",
      "train\n",
      "train loss score is :0.17319343867413986\n",
      "train acc score is :0.9419757033248082\n",
      "test\n",
      "test loss score is :0.8077462546621696\n",
      "test acc score is :0.7878757911392406\n",
      "Epoch 160\n",
      "train\n",
      "train loss score is :0.1688995264003725\n",
      "train acc score is :0.942894820971867\n",
      "test\n",
      "test loss score is :0.8131024464021755\n",
      "test acc score is :0.7923259493670886\n",
      "Epoch 161\n",
      "train\n",
      "train loss score is :0.16603577654818288\n",
      "train acc score is :0.9434143222506394\n",
      "test\n",
      "test loss score is :0.837868154237542\n",
      "test acc score is :0.7894580696202531\n",
      "Epoch 162\n",
      "train\n",
      "train loss score is :0.16653600446117656\n",
      "train acc score is :0.9447730179028133\n",
      "test\n",
      "test loss score is :0.8005888509222224\n",
      "test acc score is :0.7946993670886076\n",
      "Epoch 163\n",
      "train\n",
      "train loss score is :0.16298079510669575\n",
      "train acc score is :0.945252557544757\n",
      "test\n",
      "test loss score is :0.8371561207348788\n",
      "test acc score is :0.7842167721518988\n",
      "Epoch 164\n",
      "train\n",
      "train loss score is :0.16368240918344854\n",
      "train acc score is :0.9452125959079284\n",
      "test\n",
      "test loss score is :0.8252764302718488\n",
      "test acc score is :0.7881724683544303\n",
      "Epoch 165\n",
      "train\n",
      "train loss score is :0.16191876918801565\n",
      "train acc score is :0.9461916560102301\n",
      "test\n",
      "test loss score is :0.8265627562245236\n",
      "test acc score is :0.7882713607594937\n",
      "Epoch 166\n",
      "train\n",
      "train loss score is :0.15572797672351454\n",
      "train acc score is :0.9478900255754475\n",
      "test\n",
      "test loss score is :0.8298570387348344\n",
      "test acc score is :0.792128164556962\n",
      "Epoch 167\n",
      "train\n",
      "train loss score is :0.16469750869685731\n",
      "train acc score is :0.9449928069053708\n",
      "test\n",
      "test loss score is :0.8441146370730822\n",
      "test acc score is :0.7872824367088608\n",
      "Epoch 168\n",
      "train\n",
      "train loss score is :0.16192517183778232\n",
      "train acc score is :0.9460717710997443\n",
      "test\n",
      "test loss score is :0.8198469569788703\n",
      "test acc score is :0.7881724683544303\n",
      "Epoch 169\n",
      "train\n",
      "train loss score is :0.15654154028028935\n",
      "train acc score is :0.9480898337595908\n",
      "test\n",
      "test loss score is :0.8584797082445289\n",
      "test acc score is :0.7872824367088608\n",
      "Epoch 170\n",
      "train\n",
      "train loss score is :0.15742893075413258\n",
      "train acc score is :0.9470108695652174\n",
      "test\n",
      "test loss score is :0.8543219982728928\n",
      "test acc score is :0.7925237341772152\n",
      "Epoch 171\n",
      "train\n",
      "train loss score is :0.1556015588543223\n",
      "train acc score is :0.9482696611253197\n",
      "test\n",
      "test loss score is :0.840983500397658\n",
      "test acc score is :0.7888647151898734\n",
      "Epoch 172\n",
      "train\n",
      "train loss score is :0.1589061349839963\n",
      "train acc score is :0.946611253196931\n",
      "test\n",
      "test loss score is :0.8815825368407406\n",
      "test acc score is :0.7869857594936709\n",
      "Epoch 173\n",
      "train\n",
      "train loss score is :0.1600037396449567\n",
      "train acc score is :0.9460917519181585\n",
      "test\n",
      "test loss score is :0.8314035955486418\n",
      "test acc score is :0.7865901898734177\n",
      "Epoch 174\n",
      "train\n",
      "train loss score is :0.15432213981400061\n",
      "train acc score is :0.9472306585677749\n",
      "test\n",
      "test loss score is :0.8480520991584922\n",
      "test acc score is :0.7860957278481012\n",
      "Epoch 175\n",
      "train\n",
      "train loss score is :0.15676972148535046\n",
      "train acc score is :0.9477101982097187\n",
      "test\n",
      "test loss score is :0.8113840933464751\n",
      "test acc score is :0.7894580696202531\n",
      "Epoch 176\n",
      "train\n",
      "train loss score is :0.15903115471172363\n",
      "train acc score is :0.9460318094629157\n",
      "test\n",
      "test loss score is :0.8350430136617226\n",
      "test acc score is :0.7855023734177216\n",
      "Epoch 177\n",
      "train\n",
      "train loss score is :0.15260544696541697\n",
      "train acc score is :0.9500479539641944\n",
      "test\n",
      "test loss score is :0.8277508891835997\n",
      "test acc score is :0.7912381329113924\n",
      "Epoch 178\n",
      "train\n",
      "train loss score is :0.15416529602930903\n",
      "train acc score is :0.948289641943734\n",
      "test\n",
      "test loss score is :0.8396319182990473\n",
      "test acc score is :0.7872824367088608\n",
      "Epoch 179\n",
      "train\n",
      "train loss score is :0.15054282069187183\n",
      "train acc score is :0.9496283567774936\n",
      "test\n",
      "test loss score is :0.8370112248613865\n",
      "test acc score is :0.7939082278481012\n",
      "Epoch 180\n",
      "train\n",
      "train loss score is :0.15465405517641237\n",
      "train acc score is :0.9486492966751918\n",
      "test\n",
      "test loss score is :0.8266078848627549\n",
      "test acc score is :0.7910403481012658\n",
      "Epoch 181\n",
      "train\n",
      "train loss score is :0.15056559181464907\n",
      "train acc score is :0.9498281649616368\n",
      "test\n",
      "test loss score is :0.8323481731305394\n",
      "test acc score is :0.7931170886075949\n",
      "Epoch 182\n",
      "train\n",
      "train loss score is :0.15403399886587238\n",
      "train acc score is :0.9487891624040921\n",
      "test\n",
      "test loss score is :0.8410471262811106\n",
      "test acc score is :0.7888647151898734\n",
      "Epoch 183\n",
      "train\n",
      "train loss score is :0.15229001484544533\n",
      "train acc score is :0.949468510230179\n",
      "test\n",
      "test loss score is :0.8236791042587425\n",
      "test acc score is :0.7930181962025317\n",
      "Epoch 184\n",
      "train\n",
      "train loss score is :0.148645952172444\n",
      "train acc score is :0.948909047314578\n",
      "test\n",
      "test loss score is :0.8441831294117095\n",
      "test acc score is :0.7932159810126582\n",
      "Epoch 185\n",
      "train\n",
      "train loss score is :0.14844100874469943\n",
      "train acc score is :0.9495084718670077\n",
      "test\n",
      "test loss score is :0.8447146425141564\n",
      "test acc score is :0.7908425632911392\n",
      "Epoch 186\n",
      "train\n",
      "train loss score is :0.14632419451994969\n",
      "train acc score is :0.9510869565217391\n",
      "test\n",
      "test loss score is :0.8422150942438011\n",
      "test acc score is :0.7891613924050633\n",
      "Epoch 187\n",
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss score is :0.1472400861942326\n",
      "train acc score is :0.9513067455242967\n",
      "test\n",
      "test loss score is :0.82794852215278\n",
      "test acc score is :0.7909414556962026\n",
      "Epoch 188\n",
      "train\n",
      "train loss score is :0.14939313587468223\n",
      "train acc score is :0.9498081841432225\n",
      "test\n",
      "test loss score is :0.8484632020132451\n",
      "test acc score is :0.7908425632911392\n",
      "Epoch 189\n",
      "train\n",
      "train loss score is :0.1468553999605615\n",
      "train acc score is :0.9507472826086957\n",
      "test\n",
      "test loss score is :0.8302010759428332\n",
      "test acc score is :0.789754746835443\n",
      "Epoch 190\n",
      "train\n",
      "train loss score is :0.15147916501021141\n",
      "train acc score is :0.9493086636828645\n",
      "test\n",
      "test loss score is :0.8384543538470811\n",
      "test acc score is :0.7932159810126582\n",
      "Epoch 191\n",
      "train\n",
      "train loss score is :0.1503507299467807\n",
      "train acc score is :0.9490489130434783\n",
      "test\n",
      "test loss score is :0.8183758806295788\n",
      "test acc score is :0.7899525316455697\n",
      "Epoch 192\n",
      "train\n",
      "train loss score is :0.14812170419022633\n",
      "train acc score is :0.9507273017902813\n",
      "test\n",
      "test loss score is :0.8439961967023113\n",
      "test acc score is :0.7924248417721519\n",
      "Epoch 193\n",
      "train\n",
      "train loss score is :0.14984602768383826\n",
      "train acc score is :0.9505075127877238\n",
      "test\n",
      "test loss score is :0.8401712099962597\n",
      "test acc score is :0.794501582278481\n",
      "Epoch 194\n",
      "train\n",
      "train loss score is :0.1492568630096324\n",
      "train acc score is :0.9508471867007673\n",
      "test\n",
      "test loss score is :0.837205863545967\n",
      "test acc score is :0.7882713607594937\n",
      "Epoch 195\n",
      "train\n",
      "train loss score is :0.14335714160081217\n",
      "train acc score is :0.9521259590792839\n",
      "test\n",
      "test loss score is :0.8330268916449969\n",
      "test acc score is :0.7967761075949367\n",
      "Epoch 196\n",
      "train\n",
      "train loss score is :0.1509834895686954\n",
      "train acc score is :0.9489290281329923\n",
      "test\n",
      "test loss score is :0.8267792863181874\n",
      "test acc score is :0.7937104430379747\n",
      "Epoch 197\n",
      "train\n",
      "train loss score is :0.13741882291177046\n",
      "train acc score is :0.9539442135549873\n",
      "test\n",
      "test loss score is :0.8492307342777524\n",
      "test acc score is :0.7929193037974683\n",
      "Epoch 198\n",
      "train\n",
      "train loss score is :0.14650025983791218\n",
      "train acc score is :0.951386668797954\n",
      "test\n",
      "test loss score is :0.8261020058129407\n",
      "test acc score is :0.7923259493670886\n",
      "Epoch 199\n",
      "train\n",
      "train loss score is :0.14101133310019284\n",
      "train acc score is :0.9524456521739131\n",
      "test\n",
      "test loss score is :0.8565720145272303\n",
      "test acc score is :0.7893591772151899\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,  # set range for random shear\n",
    "    zoom_range=0.,  # set range for random zoom\n",
    "    channel_shift_range=0.,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None)\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "datagentest = ImageDataGenerator()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# alfa 0.1 beta 0.5 for nonbest, 0.1 alfa for best\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lossepoch=[]\n",
    "lossepoch_test=[]\n",
    "lossx=[]\n",
    "acctra=[]\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "skip=[]\n",
    "\n",
    "for f in range(200):\n",
    "    tr1=[]\n",
    "    tr2=[]\n",
    "    res1=[]\n",
    "    res2=[]\n",
    "    print('Epoch', f)\n",
    "    print ('train')\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
    "        K.set_learning_phase(1)\n",
    "        for i in range(len(all_model)):\n",
    "            all_model[i].layers[14].rate= 0.5\n",
    "            all_model[i].layers[16].rate= 0.5\n",
    "        inputs = [x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  1, # learning phase in TEST mode\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                 ]\n",
    "        ll = upd_bb2(inputs)\n",
    "        yhat=ll[6]\n",
    "        lossepoch.append(ll[2])\n",
    "        tr1.append(ll[2])\n",
    "        tr2.append(accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        skip.append(ll[3])\n",
    "        batches += 1\n",
    "        if batches > len(x_train) / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    m=(len(x_train) / batch_size)-int((len(x_train) / batch_size))\n",
    "    tr1[-1]*=m\n",
    "    tr2[-1]*=m\n",
    "    lossx.append(np.mean(tr1))\n",
    "    acctra.append(np.mean(tr2))\n",
    "    print ('train loss score is :'+str(np.mean(tr1)))\n",
    "    print ('train acc score is :'+str(np.mean(tr2)))\n",
    "    print ('test')\n",
    "    batchesx = 0\n",
    "    for x_batch, y_batch in datagentest.flow(x_test, y_test, batch_size=batch_size):\n",
    "        K.set_learning_phase(0)\n",
    "        for i in range(len(all_model)):\n",
    "            all_model[i].layers[14].rate= 0\n",
    "            all_model[i].layers[16].rate= 0\n",
    "        inputs = [x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  1, # learning phase in TEST mode\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                  x_batch, # X\n",
    "                  np.ones(y_batch.shape[0]), # sample weights\n",
    "                  y_batch, # y\n",
    "                 ]\n",
    "        ll = upd_test(inputs)\n",
    "        yhat=ll[6]\n",
    "        lossepoch_test.append(ll[2])\n",
    "        res1.append(ll[2])\n",
    "        res2.append(accuracy_score(np.argmax(y_batch,axis=1), np.argmax(yhat,axis=1)))\n",
    "        batchesx += 1\n",
    "        if batchesx >= len(x_test) / batch_size:\n",
    "            break\n",
    "    m=(len(x_test) / batch_size)-int((len(x_test) / batch_size))\n",
    "    res1[-1]*=m\n",
    "    res2[-1]*=m\n",
    "    loss_test.append(np.mean(res1))\n",
    "    acc_test.append(np.mean(res2))\n",
    "    print ('test loss score is :'+str(np.mean(res1)))\n",
    "    print ('test acc score is :'+str(np.mean(res2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Adam_lossepoch.csv\", lossepoch, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_lossepoch_test.csv\", lossepoch_test, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_loss_tra.csv\", lossx, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_skip.csv\", skip, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_acc_tra.csv\", acctra, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_loss_test.csv\", loss_test, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"Adam_acc_test.csv\", acc_test, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.641719488117396,\n",
       " 1.2207874412960409,\n",
       " 1.0870582391234005,\n",
       " 0.9907171572451396,\n",
       " 0.9271227505505847,\n",
       " 0.8816479871340115,\n",
       " 0.8415727243017967,\n",
       " 0.8059592935854517,\n",
       " 0.7785042186679743,\n",
       " 0.7504598098566465,\n",
       " 0.735496882720829,\n",
       " 0.7032908971428566,\n",
       " 0.6880906758939519,\n",
       " 0.6676658841273974,\n",
       " 0.6401928688787744,\n",
       " 0.6388818841532368,\n",
       " 0.6170150778444526,\n",
       " 0.6056280717482347,\n",
       " 0.5933442163231123,\n",
       " 0.5740721527763339,\n",
       " 0.5683817454539907,\n",
       " 0.5539049276381808,\n",
       " 0.5480554912934827,\n",
       " 0.5318290164403598,\n",
       " 0.5251559565020034,\n",
       " 0.5172608327454008,\n",
       " 0.5078341996540194,\n",
       " 0.49770000213971527,\n",
       " 0.48937131249157667,\n",
       " 0.48095689885451665,\n",
       " 0.46822806092365016,\n",
       " 0.4655147509273056,\n",
       " 0.4581878584573793,\n",
       " 0.4563413394991394,\n",
       " 0.44629513420869626,\n",
       " 0.4386080483169964,\n",
       " 0.4295955555289603,\n",
       " 0.4291493937068278,\n",
       " 0.42031252566162886,\n",
       " 0.410697263553548,\n",
       " 0.40847515494889003,\n",
       " 0.40545050681704453,\n",
       " 0.3977651999467779,\n",
       " 0.3944968752505834,\n",
       " 0.38484500879255096,\n",
       " 0.3805092279525364,\n",
       " 0.3812742710990064,\n",
       " 0.37399929229293943,\n",
       " 0.36716907349465144,\n",
       " 0.3594636295343299,\n",
       " 0.35940375979370476,\n",
       " 0.3592611526703591,\n",
       " 0.34568424776310813,\n",
       " 0.3485871652793854,\n",
       " 0.3453588315173793,\n",
       " 0.34314845873952826,\n",
       " 0.3393576076573423,\n",
       " 0.3295720146249627,\n",
       " 0.3310067721683046,\n",
       " 0.3247027968430458,\n",
       " 0.31406880074830923,\n",
       " 0.31852808303159214,\n",
       " 0.3155598806126801,\n",
       " 0.31193229483673945,\n",
       " 0.31183839013890535,\n",
       " 0.30377252174117375,\n",
       " 0.3045716044133353,\n",
       " 0.2945753939621284,\n",
       " 0.29265679497166974,\n",
       " 0.2984138603805733,\n",
       " 0.29134017608278545,\n",
       " 0.2890420537203779,\n",
       " 0.28319376043956296,\n",
       " 0.2798684125532732,\n",
       " 0.28525443747639656,\n",
       " 0.2738091420772893,\n",
       " 0.2752924677403763,\n",
       " 0.2777312871002023,\n",
       " 0.2642132794327291,\n",
       " 0.26697749771234935,\n",
       " 0.2657050411586109,\n",
       " 0.2669241102817266,\n",
       " 0.26281417015454045,\n",
       " 0.25861703387230556,\n",
       " 0.2608697992628035,\n",
       " 0.2577705072129474,\n",
       " 0.2559174625369746,\n",
       " 0.24829728433581263,\n",
       " 0.25403760411702764,\n",
       " 0.24382166997970217,\n",
       " 0.2479287834023423,\n",
       " 0.2465834913446623,\n",
       " 0.2367650110731878,\n",
       " 0.23983611296052518,\n",
       " 0.23645506360951593,\n",
       " 0.22780835189287316,\n",
       " 0.23402653500209075,\n",
       " 0.23341474477249338,\n",
       " 0.2322481539138519,\n",
       " 0.22716388096818535,\n",
       " 0.22750166223844145,\n",
       " 0.23169419766806276,\n",
       " 0.22280007068191648,\n",
       " 0.2246598153496566,\n",
       " 0.22610342160553273,\n",
       " 0.22402193603556023,\n",
       " 0.22157931127263913,\n",
       " 0.21450172522869868,\n",
       " 0.21831882819342796,\n",
       " 0.213719819712898,\n",
       " 0.21230610578185152,\n",
       " 0.21348058499986558,\n",
       " 0.20452996362429446,\n",
       " 0.20775710332119252,\n",
       " 0.20763500078159677,\n",
       " 0.2058580216934995,\n",
       " 0.20650413882968677,\n",
       " 0.21365307393910177,\n",
       " 0.19622010601889295,\n",
       " 0.20180661362760208,\n",
       " 0.19857309444728868,\n",
       " 0.2058658217892165,\n",
       " 0.19857679256011762,\n",
       " 0.18913482642158522,\n",
       " 0.20366881130372777,\n",
       " 0.193963119374288,\n",
       " 0.1963072499484205,\n",
       " 0.19549087403089646,\n",
       " 0.19392477497077354,\n",
       " 0.19066527602084152,\n",
       " 0.18679164579647886,\n",
       " 0.189046649452861,\n",
       " 0.1879776011475974,\n",
       " 0.19431644335122364,\n",
       " 0.1830834288416845,\n",
       " 0.18672388335666085,\n",
       " 0.1808813280375946,\n",
       " 0.18338990007596248,\n",
       " 0.18535025276796288,\n",
       " 0.18239305330359418,\n",
       " 0.18182685656849382,\n",
       " 0.17997751759408076,\n",
       " 0.181668031884505,\n",
       " 0.17526601222069824,\n",
       " 0.17578990237258585,\n",
       " 0.18221335461758592,\n",
       " 0.1788490849506596,\n",
       " 0.17844201896406348,\n",
       " 0.179191410055627,\n",
       " 0.1716182321557761,\n",
       " 0.17377258578072424,\n",
       " 0.17410825187211756,\n",
       " 0.1754921544938708,\n",
       " 0.16855501747020826,\n",
       " 0.17584845074035627,\n",
       " 0.16816267616513286,\n",
       " 0.16991719645459938,\n",
       " 0.16554292590092973,\n",
       " 0.16172379499201275,\n",
       " 0.17319343867413986,\n",
       " 0.1688995264003725,\n",
       " 0.16603577654818288,\n",
       " 0.16653600446117656,\n",
       " 0.16298079510669575,\n",
       " 0.16368240918344854,\n",
       " 0.16191876918801565,\n",
       " 0.15572797672351454,\n",
       " 0.16469750869685731,\n",
       " 0.16192517183778232,\n",
       " 0.15654154028028935,\n",
       " 0.15742893075413258,\n",
       " 0.1556015588543223,\n",
       " 0.1589061349839963,\n",
       " 0.1600037396449567,\n",
       " 0.15432213981400061,\n",
       " 0.15676972148535046,\n",
       " 0.15903115471172363,\n",
       " 0.15260544696541697,\n",
       " 0.15416529602930903,\n",
       " 0.15054282069187183,\n",
       " 0.15465405517641237,\n",
       " 0.15056559181464907,\n",
       " 0.15403399886587238,\n",
       " 0.15229001484544533,\n",
       " 0.148645952172444,\n",
       " 0.14844100874469943,\n",
       " 0.14632419451994969,\n",
       " 0.1472400861942326,\n",
       " 0.14939313587468223,\n",
       " 0.1468553999605615,\n",
       " 0.15147916501021141,\n",
       " 0.1503507299467807,\n",
       " 0.14812170419022633,\n",
       " 0.14984602768383826,\n",
       " 0.1492568630096324,\n",
       " 0.14335714160081217,\n",
       " 0.1509834895686954,\n",
       " 0.13741882291177046,\n",
       " 0.14650025983791218,\n",
       " 0.14101133310019284]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42844868925831203,\n",
       " 0.5723905051150895,\n",
       " 0.6222826086956522,\n",
       " 0.6607057225063938,\n",
       " 0.6831042199488491,\n",
       " 0.7005674552429667,\n",
       " 0.7148937020460358,\n",
       " 0.72818094629156,\n",
       " 0.7354739450127877,\n",
       " 0.7472026854219949,\n",
       " 0.7521779092071611,\n",
       " 0.7605099104859335,\n",
       " 0.7692615089514067,\n",
       " 0.7768342391304348,\n",
       " 0.7838075447570333,\n",
       " 0.7850263746803069,\n",
       " 0.792219469309463,\n",
       " 0.7946571291560103,\n",
       " 0.7986333120204604,\n",
       " 0.8072450447570333,\n",
       " 0.8092231457800512,\n",
       " 0.8136588874680307,\n",
       " 0.8146978900255755,\n",
       " 0.8222506393861893,\n",
       " 0.8208320012787724,\n",
       " 0.8265864769820972,\n",
       " 0.8299432544757033,\n",
       " 0.8337396099744245,\n",
       " 0.8361772698209718,\n",
       " 0.8385549872122762,\n",
       " 0.8415720907928389,\n",
       " 0.8434303069053708,\n",
       " 0.844309462915601,\n",
       " 0.8453085038363172,\n",
       " 0.850263746803069,\n",
       " 0.8519621163682864,\n",
       " 0.8538802749360613,\n",
       " 0.8550191815856778,\n",
       " 0.8572570332480819,\n",
       " 0.8623321611253197,\n",
       " 0.863031489769821,\n",
       " 0.863590952685422,\n",
       " 0.8651694373401535,\n",
       " 0.8657488810741688,\n",
       " 0.8706441815856778,\n",
       " 0.871463395140665,\n",
       " 0.8717830882352942,\n",
       " 0.8734414961636828,\n",
       " 0.8759590792838875,\n",
       " 0.8794157608695652,\n",
       " 0.8802149936061381,\n",
       " 0.8783567774936062,\n",
       " 0.8828924232736572,\n",
       " 0.8813139386189258,\n",
       " 0.8838914641943734,\n",
       " 0.8836716751918159,\n",
       " 0.8849904092071611,\n",
       " 0.8879076086956522,\n",
       " 0.8896059782608695,\n",
       " 0.8907848465473146,\n",
       " 0.8940816815856778,\n",
       " 0.8934822570332481,\n",
       " 0.893662084398977,\n",
       " 0.8950607416879796,\n",
       " 0.8938219309462916,\n",
       " 0.8977181905370843,\n",
       " 0.8970588235294118,\n",
       " 0.9009351023017903,\n",
       " 0.9012947570332481,\n",
       " 0.899616368286445,\n",
       " 0.9033927429667519,\n",
       " 0.9024536445012787,\n",
       " 0.9051110933503836,\n",
       " 0.9055706521739131,\n",
       " 0.9041520140664961,\n",
       " 0.9068893861892583,\n",
       " 0.9064697890025576,\n",
       " 0.9070692135549873,\n",
       " 0.9123041879795396,\n",
       " 0.9106657608695652,\n",
       " 0.9104259910485933,\n",
       " 0.9113650895140665,\n",
       " 0.9114849744245525,\n",
       " 0.9121443414322251,\n",
       " 0.910905530690537,\n",
       " 0.9143022698209718,\n",
       " 0.9144621163682864,\n",
       " 0.9171195652173914,\n",
       " 0.9149616368286445,\n",
       " 0.9169996803069054,\n",
       " 0.9151214833759591,\n",
       " 0.9169197570332481,\n",
       " 0.9196371483375959,\n",
       " 0.9191576086956522,\n",
       " 0.9205562659846548,\n",
       " 0.9229339833759591,\n",
       " 0.921875,\n",
       " 0.9209159207161125,\n",
       " 0.9217950767263428,\n",
       " 0.9235134271099744,\n",
       " 0.9232137148337596,\n",
       " 0.9211956521739131,\n",
       " 0.9237931585677749,\n",
       " 0.9240728900255755,\n",
       " 0.9247122762148338,\n",
       " 0.9238531010230179,\n",
       " 0.9251118925831202,\n",
       " 0.9280490728900256,\n",
       " 0.9258112212276215,\n",
       " 0.9284287084398977,\n",
       " 0.9287084398976982,\n",
       " 0.9285885549872123,\n",
       " 0.9316256393861893,\n",
       " 0.9301670396419437,\n",
       " 0.9311660805626598,\n",
       " 0.9293877877237852,\n",
       " 0.9309063299232737,\n",
       " 0.9286285166240409,\n",
       " 0.933843510230179,\n",
       " 0.9315656969309463,\n",
       " 0.9331641624040921,\n",
       " 0.9311860613810742,\n",
       " 0.9326246803069054,\n",
       " 0.9368606138107417,\n",
       " 0.931046195652174,\n",
       " 0.9354020140664961,\n",
       " 0.9340033567774936,\n",
       " 0.9347026854219949,\n",
       " 0.9355418797953964,\n",
       " 0.9357217071611253,\n",
       " 0.9361213235294118,\n",
       " 0.9392183503836317,\n",
       " 0.9361812659846548,\n",
       " 0.9355019181585678,\n",
       " 0.9379995204603581,\n",
       " 0.9383591751918159,\n",
       " 0.9383791560102301,\n",
       " 0.939298273657289,\n",
       " 0.9376598465473146,\n",
       " 0.93911844629156,\n",
       " 0.9380794437340153,\n",
       " 0.9381993286445013,\n",
       " 0.9404571611253197,\n",
       " 0.9401374680306905,\n",
       " 0.9412963554987213,\n",
       " 0.9400175831202046,\n",
       " 0.9404971227621484,\n",
       " 0.9406969309462916,\n",
       " 0.94059702685422,\n",
       " 0.9412364130434783,\n",
       " 0.9419557225063938,\n",
       " 0.9415760869565217,\n",
       " 0.9401574488491049,\n",
       " 0.9426550511508951,\n",
       " 0.9399576406649617,\n",
       " 0.9433343989769821,\n",
       " 0.943454283887468,\n",
       " 0.943574168797954,\n",
       " 0.9468310421994884,\n",
       " 0.9419757033248082,\n",
       " 0.942894820971867,\n",
       " 0.9434143222506394,\n",
       " 0.9447730179028133,\n",
       " 0.945252557544757,\n",
       " 0.9452125959079284,\n",
       " 0.9461916560102301,\n",
       " 0.9478900255754475,\n",
       " 0.9449928069053708,\n",
       " 0.9460717710997443,\n",
       " 0.9480898337595908,\n",
       " 0.9470108695652174,\n",
       " 0.9482696611253197,\n",
       " 0.946611253196931,\n",
       " 0.9460917519181585,\n",
       " 0.9472306585677749,\n",
       " 0.9477101982097187,\n",
       " 0.9460318094629157,\n",
       " 0.9500479539641944,\n",
       " 0.948289641943734,\n",
       " 0.9496283567774936,\n",
       " 0.9486492966751918,\n",
       " 0.9498281649616368,\n",
       " 0.9487891624040921,\n",
       " 0.949468510230179,\n",
       " 0.948909047314578,\n",
       " 0.9495084718670077,\n",
       " 0.9510869565217391,\n",
       " 0.9513067455242967,\n",
       " 0.9498081841432225,\n",
       " 0.9507472826086957,\n",
       " 0.9493086636828645,\n",
       " 0.9490489130434783,\n",
       " 0.9507273017902813,\n",
       " 0.9505075127877238,\n",
       " 0.9508471867007673,\n",
       " 0.9521259590792839,\n",
       " 0.9489290281329923,\n",
       " 0.9539442135549873,\n",
       " 0.951386668797954,\n",
       " 0.9524456521739131]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acctra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2766623463057265,\n",
       " 1.0571034959034076,\n",
       " 0.9883694147007375,\n",
       " 0.9352454394102097,\n",
       " 0.873243958512439,\n",
       " 0.8385285061748722,\n",
       " 0.8119883676872978,\n",
       " 0.8049572643977178,\n",
       " 0.7795245270185833,\n",
       " 0.7647297640767279,\n",
       " 0.7321994197142275,\n",
       " 0.7086206377495693,\n",
       " 0.715099998478648,\n",
       " 0.7075017805718169,\n",
       " 0.7313109849449955,\n",
       " 0.7051068155825893,\n",
       " 0.692116311645206,\n",
       " 0.6818106755425658,\n",
       " 0.7009423072390919,\n",
       " 0.6814848095933094,\n",
       " 0.6652104606545424,\n",
       " 0.6726734614636325,\n",
       " 0.6494818803253053,\n",
       " 0.6672363333121131,\n",
       " 0.6590828142022784,\n",
       " 0.6486156831813764,\n",
       " 0.6530917890464203,\n",
       " 0.6782885663494279,\n",
       " 0.6566752602782431,\n",
       " 0.65690671284742,\n",
       " 0.6631265879620479,\n",
       " 0.6679428792263888,\n",
       " 0.6737789783296706,\n",
       " 0.6602060240280779,\n",
       " 0.6795235332808917,\n",
       " 0.6662027281296404,\n",
       " 0.6689705282826967,\n",
       " 0.654323241213643,\n",
       " 0.6729629630152183,\n",
       " 0.6667796199363244,\n",
       " 0.6683753928806209,\n",
       " 0.6568412196032608,\n",
       " 0.673943053035042,\n",
       " 0.6575209800201126,\n",
       " 0.6729878636100625,\n",
       " 0.6654063350037683,\n",
       " 0.6741555119051209,\n",
       " 0.6660121041291123,\n",
       " 0.6661314421062228,\n",
       " 0.6790520107444329,\n",
       " 0.6918040232945092,\n",
       " 0.6757061394709575,\n",
       " 0.6796669159320337,\n",
       " 0.6944731258893315,\n",
       " 0.6898662756326832,\n",
       " 0.6758865523564664,\n",
       " 0.6829265734251542,\n",
       " 0.684836878570952,\n",
       " 0.7158046567553207,\n",
       " 0.6800186943404282,\n",
       " 0.7031073270342018,\n",
       " 0.6986302314679834,\n",
       " 0.708544721709022,\n",
       " 0.6988055366504041,\n",
       " 0.7152682170271873,\n",
       " 0.6955412247135669,\n",
       " 0.7157552313955524,\n",
       " 0.7091256788448442,\n",
       " 0.7205813318208049,\n",
       " 0.6985359842641444,\n",
       " 0.7164165592646297,\n",
       " 0.7182647591527505,\n",
       " 0.7220296837106536,\n",
       " 0.7253695120917091,\n",
       " 0.710849106877665,\n",
       " 0.7317096968240375,\n",
       " 0.7268054546151734,\n",
       " 0.7106434343547761,\n",
       " 0.7308471785693229,\n",
       " 0.7323652026774008,\n",
       " 0.7417807930349549,\n",
       " 0.7229164374780052,\n",
       " 0.7202206403017044,\n",
       " 0.7411872289037402,\n",
       " 0.7175181428842907,\n",
       " 0.7250878697709192,\n",
       " 0.7644717202910895,\n",
       " 0.7364264402208449,\n",
       " 0.7259468910626218,\n",
       " 0.7606563028655474,\n",
       " 0.7367977100082591,\n",
       " 0.7279787308807615,\n",
       " 0.7307857846534704,\n",
       " 0.7261197661297231,\n",
       " 0.7456963370683827,\n",
       " 0.7656797910038429,\n",
       " 0.7397399369297148,\n",
       " 0.7637062619758558,\n",
       " 0.7589647887816912,\n",
       " 0.7474272448711002,\n",
       " 0.7726969472545234,\n",
       " 0.7575111997938608,\n",
       " 0.7819103532105307,\n",
       " 0.77578111200393,\n",
       " 0.7757955126558678,\n",
       " 0.7573125001184547,\n",
       " 0.7667057769773882,\n",
       " 0.777076015555406,\n",
       " 0.7919759122253973,\n",
       " 0.7898397635244117,\n",
       " 0.7800651117216183,\n",
       " 0.7780203102510187,\n",
       " 0.7861694840690757,\n",
       " 0.7764823817754094,\n",
       " 0.7957785889694963,\n",
       " 0.7813862643287152,\n",
       " 0.7641867172868946,\n",
       " 0.7475279030166094,\n",
       " 0.771726907525636,\n",
       " 0.7874066897585422,\n",
       " 0.7835298703063892,\n",
       " 0.7789860920438284,\n",
       " 0.781582850444166,\n",
       " 0.7770941686592524,\n",
       " 0.7660547422268723,\n",
       " 0.7907858338159851,\n",
       " 0.781550143338457,\n",
       " 0.7996909199636194,\n",
       " 0.7890826384713755,\n",
       " 0.7984861736244793,\n",
       " 0.7768058627843857,\n",
       " 0.7910490493419804,\n",
       " 0.8262491758111157,\n",
       " 0.8034765493077568,\n",
       " 0.7962926594139654,\n",
       " 0.7974663967195945,\n",
       " 0.8121949558771109,\n",
       " 0.8163358229625074,\n",
       " 0.8000170609241799,\n",
       " 0.8041880160947389,\n",
       " 0.7942795245141923,\n",
       " 0.8019487408897544,\n",
       " 0.7906853384986708,\n",
       " 0.7991308943380283,\n",
       " 0.8220266129208517,\n",
       " 0.7833029978165899,\n",
       " 0.7826614754298066,\n",
       " 0.8348440784442274,\n",
       " 0.8232591587908661,\n",
       " 0.8071713125026678,\n",
       " 0.8213424525117572,\n",
       " 0.8062562663343888,\n",
       " 0.8039702286920215,\n",
       " 0.8139119589630561,\n",
       " 0.8161188696004167,\n",
       " 0.8012760528186454,\n",
       " 0.8130686590565911,\n",
       " 0.8189215388479112,\n",
       " 0.8052408348155927,\n",
       " 0.8077462546621696,\n",
       " 0.8131024464021755,\n",
       " 0.837868154237542,\n",
       " 0.8005888509222224,\n",
       " 0.8371561207348788,\n",
       " 0.8252764302718488,\n",
       " 0.8265627562245236,\n",
       " 0.8298570387348344,\n",
       " 0.8441146370730822,\n",
       " 0.8198469569788703,\n",
       " 0.8584797082445289,\n",
       " 0.8543219982728928,\n",
       " 0.840983500397658,\n",
       " 0.8815825368407406,\n",
       " 0.8314035955486418,\n",
       " 0.8480520991584922,\n",
       " 0.8113840933464751,\n",
       " 0.8350430136617226,\n",
       " 0.8277508891835997,\n",
       " 0.8396319182990473,\n",
       " 0.8370112248613865,\n",
       " 0.8266078848627549,\n",
       " 0.8323481731305394,\n",
       " 0.8410471262811106,\n",
       " 0.8236791042587425,\n",
       " 0.8441831294117095,\n",
       " 0.8447146425141564,\n",
       " 0.8422150942438011,\n",
       " 0.82794852215278,\n",
       " 0.8484632020132451,\n",
       " 0.8302010759428332,\n",
       " 0.8384543538470811,\n",
       " 0.8183758806295788,\n",
       " 0.8439961967023113,\n",
       " 0.8401712099962597,\n",
       " 0.837205863545967,\n",
       " 0.8330268916449969,\n",
       " 0.8267792863181874,\n",
       " 0.8492307342777524,\n",
       " 0.8261020058129407,\n",
       " 0.8565720145272303]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5346123417721519,\n",
       " 0.6252966772151899,\n",
       " 0.6438884493670886,\n",
       " 0.666435917721519,\n",
       " 0.689873417721519,\n",
       " 0.7035205696202531,\n",
       " 0.7146954113924051,\n",
       " 0.7169699367088608,\n",
       " 0.725870253164557,\n",
       " 0.7317049050632911,\n",
       " 0.7474287974683544,\n",
       " 0.7524723101265823,\n",
       " 0.7537579113924051,\n",
       " 0.7539556962025317,\n",
       " 0.7467365506329114,\n",
       " 0.756131329113924,\n",
       " 0.7611748417721519,\n",
       " 0.7667128164556962,\n",
       " 0.7631526898734177,\n",
       " 0.7676028481012658,\n",
       " 0.7730419303797469,\n",
       " 0.7731408227848101,\n",
       " 0.7745253164556962,\n",
       " 0.7768987341772152,\n",
       " 0.778184335443038,\n",
       " 0.7783821202531646,\n",
       " 0.7797666139240507,\n",
       " 0.7743275316455697,\n",
       " 0.7806566455696202,\n",
       " 0.7808544303797469,\n",
       " 0.7818433544303798,\n",
       " 0.7777887658227848,\n",
       " 0.7761075949367089,\n",
       " 0.7780854430379747,\n",
       " 0.7787776898734177,\n",
       " 0.7804588607594937,\n",
       " 0.7822389240506329,\n",
       " 0.7857990506329114,\n",
       " 0.7852056962025317,\n",
       " 0.7813488924050633,\n",
       " 0.7837223101265823,\n",
       " 0.7876780063291139,\n",
       " 0.7827333860759493,\n",
       " 0.786689082278481,\n",
       " 0.7861946202531646,\n",
       " 0.7865901898734177,\n",
       " 0.7847112341772152,\n",
       " 0.787381329113924,\n",
       " 0.7908425632911392,\n",
       " 0.7877768987341772,\n",
       " 0.7884691455696202,\n",
       " 0.791435917721519,\n",
       " 0.7880735759493671,\n",
       " 0.7857001582278481,\n",
       " 0.7887658227848101,\n",
       " 0.7944026898734177,\n",
       " 0.7928204113924051,\n",
       " 0.7909414556962026,\n",
       " 0.784315664556962,\n",
       " 0.7917325949367089,\n",
       " 0.7858979430379747,\n",
       " 0.7877768987341772,\n",
       " 0.7884691455696202,\n",
       " 0.7874802215189873,\n",
       " 0.7877768987341772,\n",
       " 0.7876780063291139,\n",
       " 0.7827333860759493,\n",
       " 0.7880735759493671,\n",
       " 0.7863924050632911,\n",
       " 0.7898536392405063,\n",
       " 0.7851068037974683,\n",
       " 0.7941060126582279,\n",
       " 0.7851068037974683,\n",
       " 0.7851068037974683,\n",
       " 0.7828322784810127,\n",
       " 0.7844145569620253,\n",
       " 0.788370253164557,\n",
       " 0.7912381329113924,\n",
       " 0.7904469936708861,\n",
       " 0.7919303797468354,\n",
       " 0.7889636075949367,\n",
       " 0.7863924050632911,\n",
       " 0.7910403481012658,\n",
       " 0.790743670886076,\n",
       " 0.7916337025316456,\n",
       " 0.7895569620253164,\n",
       " 0.7891613924050633,\n",
       " 0.7930181962025317,\n",
       " 0.7916337025316456,\n",
       " 0.7856012658227848,\n",
       " 0.791435917721519,\n",
       " 0.7913370253164557,\n",
       " 0.7946004746835443,\n",
       " 0.7903481012658228,\n",
       " 0.7906447784810127,\n",
       " 0.7850079113924051,\n",
       " 0.7884691455696202,\n",
       " 0.7882713607594937,\n",
       " 0.784315664556962,\n",
       " 0.7906447784810127,\n",
       " 0.784315664556962,\n",
       " 0.7900514240506329,\n",
       " 0.7849090189873418,\n",
       " 0.786689082278481,\n",
       " 0.7893591772151899,\n",
       " 0.7915348101265823,\n",
       " 0.7839200949367089,\n",
       " 0.7928204113924051,\n",
       " 0.7844145569620253,\n",
       " 0.7865901898734177,\n",
       " 0.7899525316455697,\n",
       " 0.7905458860759493,\n",
       " 0.7888647151898734,\n",
       " 0.7952927215189873,\n",
       " 0.7837223101265823,\n",
       " 0.7894580696202531,\n",
       " 0.7878757911392406,\n",
       " 0.7939082278481012,\n",
       " 0.7925237341772152,\n",
       " 0.7867879746835443,\n",
       " 0.7858979430379747,\n",
       " 0.7875791139240507,\n",
       " 0.7862935126582279,\n",
       " 0.7892602848101266,\n",
       " 0.790743670886076,\n",
       " 0.7875791139240507,\n",
       " 0.7913370253164557,\n",
       " 0.7890625,\n",
       " 0.7889636075949367,\n",
       " 0.7874802215189873,\n",
       " 0.7928204113924051,\n",
       " 0.7924248417721519,\n",
       " 0.7835245253164557,\n",
       " 0.7850079113924051,\n",
       " 0.7878757911392406,\n",
       " 0.7904469936708861,\n",
       " 0.7913370253164557,\n",
       " 0.7832278481012658,\n",
       " 0.7879746835443038,\n",
       " 0.7884691455696202,\n",
       " 0.7861946202531646,\n",
       " 0.7901503164556962,\n",
       " 0.7913370253164557,\n",
       " 0.7931170886075949,\n",
       " 0.7871835443037974,\n",
       " 0.791435917721519,\n",
       " 0.7928204113924051,\n",
       " 0.7827333860759493,\n",
       " 0.7875791139240507,\n",
       " 0.7911392405063291,\n",
       " 0.7900514240506329,\n",
       " 0.787381329113924,\n",
       " 0.7918314873417721,\n",
       " 0.7925237341772152,\n",
       " 0.7917325949367089,\n",
       " 0.7925237341772152,\n",
       " 0.7899525316455697,\n",
       " 0.7875791139240507,\n",
       " 0.7916337025316456,\n",
       " 0.7878757911392406,\n",
       " 0.7923259493670886,\n",
       " 0.7894580696202531,\n",
       " 0.7946993670886076,\n",
       " 0.7842167721518988,\n",
       " 0.7881724683544303,\n",
       " 0.7882713607594937,\n",
       " 0.792128164556962,\n",
       " 0.7872824367088608,\n",
       " 0.7881724683544303,\n",
       " 0.7872824367088608,\n",
       " 0.7925237341772152,\n",
       " 0.7888647151898734,\n",
       " 0.7869857594936709,\n",
       " 0.7865901898734177,\n",
       " 0.7860957278481012,\n",
       " 0.7894580696202531,\n",
       " 0.7855023734177216,\n",
       " 0.7912381329113924,\n",
       " 0.7872824367088608,\n",
       " 0.7939082278481012,\n",
       " 0.7910403481012658,\n",
       " 0.7931170886075949,\n",
       " 0.7888647151898734,\n",
       " 0.7930181962025317,\n",
       " 0.7932159810126582,\n",
       " 0.7908425632911392,\n",
       " 0.7891613924050633,\n",
       " 0.7909414556962026,\n",
       " 0.7908425632911392,\n",
       " 0.789754746835443,\n",
       " 0.7932159810126582,\n",
       " 0.7899525316455697,\n",
       " 0.7924248417721519,\n",
       " 0.794501582278481,\n",
       " 0.7882713607594937,\n",
       " 0.7967761075949367,\n",
       " 0.7937104430379747,\n",
       " 0.7929193037974683,\n",
       " 0.7923259493670886,\n",
       " 0.7893591772151899]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7967761075949367, 195)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(acc_test), np.argmax(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6486156831813764, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(loss_test), np.argmin(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
